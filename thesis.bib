
@inproceedings{lowe_object_1999,
	title = {Object recognition from local scale-invariant features},
	volume = {2},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=790410},
	urldate = {2013-01-15},
	booktitle = {Computer Vision, 1999. The Proceedings of the Seventh {IEEE} International Conference on},
	author = {Lowe, D. G.},
	year = {1999},
	note = {07873},
	pages = {1150--1157},
	file = {00790410.pdf:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/DKIH3U5W/00790410.pdf:application/pdf}
}

@inproceedings{sinapov_object_2011,
	title = {Object category recognition by a humanoid robot using behavior-grounded relational learning},
	doi = {10.1109/ICRA.2011.5980417},
	abstract = {The ability to form and recognize object categories is fundamental to human intelligence. This paper proposes a behavior-grounded relational classification model that allows a robot to recognize the categories of household objects. In the proposed approach, the robot initially explores the objects by applying five exploratory behaviors (lift, shake, drop, crush and push) on them while recording the proprioceptive and auditory sensory feedback produced by each interaction. The sensorimotor data is used to estimate multiple measures of similarity between the objects, each corresponding to a specific coupling between an exploratory behavior and a sensory modality. A graph-based recognition model is trained by extracting features from the estimated similarity relations, allowing the robot to recognize the category memberships of a novel object based on the object's similarity to the set of familiar objects. The framework was evaluated on an upper-torso humanoid robot with two large sets of household objects. The results show that the robot's model is able to recognize complex object categories (e.g., metal objects, empty bottles, etc.) significantly better than chance.},
	booktitle = {2011 {IEEE} International Conference on Robotics and Automation ({ICRA})},
	author = {Sinapov, J. and Stoytchev, A.},
	year = {2011},
	note = {00018},
	keywords = {auditory sensory feedback, behavior-grounded relational learning, Context, domestic appliances, feature extraction, feedback, graph-based recognition model, household object, human intelligence, humanoid robots, image classification, Joints, learning (artificial intelligence), Metals, mobile robots, object category recognition, Object recognition, pattern matching, proprioceptive sensory feedback, Robot sensing systems, robot vision, sensorimotor data, sensory aids, similarity measure, Support vector machines, upper-torso humanoid robot},
	pages = {184--190},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/RDIIHAAC/abs_all.html:text/html;IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/AMA5FVKB/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/5KTZ9AES/Sinapov and Stoytchev - 2011 - Object category recognition by a humanoid robot us.pdf:application/pdf;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/HKCJS6NZ/Sinapov and Stoytchev - 2011 - Object category recognition by a humanoid robot us.pdf:application/pdf}
}

@article{lowe_distinctive_2004,
	title = {Distinctive Image Features from Scale-Invariant Keypoints},
	volume = {60},
	issn = {0920-5691, 1573-1405},
	url = {http://link.springer.com/article/10.1023/B%3AVISI.0000029664.99615.94},
	doi = {10.1023/B:VISI.0000029664.99615.94},
	abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
	language = {en},
	number = {2},
	urldate = {2013-08-29},
	journal = {International Journal of Computer Vision},
	author = {Lowe, David G.},
	month = nov,
	year = {2004},
	note = {21760},
	keywords = {Artificial Intelligence (incl. Robotics), Automation and Robotics, Computer Imaging, Graphics and Computer Vision, image matching, image processing, invariant features, Object recognition, scale invariance},
	pages = {91--110},
	file = {Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/SM44TSKZ/Lowe - 2004 - Distinctive Image Features from Scale-Invariant Ke.pdf:application/pdf;Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/ZN29JE27/BVISI.0000029664.99615.html:text/html}
}

@inproceedings{csurka_visual_2004,
	title = {Visual categorization with bags of keypoints},
	volume = {1},
	url = {http://217.109.185.161/layout/set/print/content/download/20785/148346/file/2004_010.pdf},
	urldate = {2013-08-28},
	booktitle = {Workshop on statistical learning in computer vision, {ECCV}},
	author = {Csurka, Gabriella and Dance, Christopher and Fan, Lixin and Willamowski, Jutta and Bray, CÃ©dric},
	year = {2004},
	note = {02136},
	pages = {22},
	file = {2004_010.pdf:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/MEIFIHD3/2004_010.pdf:application/pdf;2004_010.pdf:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/87GRBQTR/2004_010.pdf:application/pdf}
}

@inproceedings{sinapov_interactive_2009,
	title = {Interactive learning of the acoustic properties of household objects},
	doi = {10.1109/ROBOT.2009.5152802},
	abstract = {Human beings can perceive object properties such as size, weight, and material type based solely on the sounds that the objects make when an action is performed on them. In order to be successful, the household robots of the near future must also be capable of learning and reasoning about the acoustic properties of everyday objects. Such an ability would allow a robot to detect and classify various interactions with objects that occur outside of the robot's field of view. This paper presents a framework that allows a robot to infer the object and the type of behavioral interaction performed with it from the sounds generated by the object during the interaction. The framework is evaluated on a 7-d.o.f. Barrett {WAM} robot which performs grasping, shaking, dropping, pushing and tapping behaviors on 36 different household objects. The results show that the robot can learn models that can be used to recognize objects (and behaviors performed on objects) from the sounds generated during the interaction. In addition, the robot can use the learned models to estimate the similarity between two objects in terms of their acoustic properties.},
	booktitle = {{IEEE} International Conference on Robotics and Automation, 2009. {ICRA} '09},
	author = {Sinapov, J. and Wiemer, M. and Stoytchev, A.},
	month = may,
	year = {2009},
	keywords = {Acoustic materials, acoustic properties, Acoustic signal detection, Barrett {WAM} robot, household objects, household robots, Human robot interaction, Information resources, interactive learning, Laboratories, learning (artificial intelligence), manipulators, microphones, object detection, reasoning, Robotics and automation, Robot sensing systems},
	pages = {2518--2524},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/GCWIKXJM/abs_all.html:text/html;IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/3M2MIKFU/abs_all.html:text/html;IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/ATR74864/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/TJEHDRKH/Sinapov et al. - 2009 - Interactive learning of the acoustic properties of.pdf:application/pdf;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/7K89EGPT/Sinapov et al. - 2009 - Interactive learning of the acoustic properties of.pdf:application/pdf;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/ADWWCQHC/Sinapov et al. - 2009 - Interactive learning of the acoustic properties of.pdf:application/pdf}
}

@article{juang_hidden_1991,
	title = {Hidden Markov Models for Speech Recognition},
	volume = {33},
	issn = {0040-1706},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00401706.1991.10484833},
	doi = {10.1080/00401706.1991.10484833},
	abstract = {The use of hidden Markov models for speech recognition has become predominant in the last several years, as evidenced by the number of published papers and talks at major speech conferences. The reasons this method has become so popular are the inherent statistical (mathematically precise) framework; the ease and availability of training algorithms for cstimating the parameters of the models from finite training sets of speech data; the flexibility of the resulting recognition system in which one can easily change the size, type, or architecture of the models to suit particular words, sounds, and so forth; and the ease of implementation of the overall recognition system. In this expository article, we address the role of statistical methods in this powerful technology as applied to speech recognition and discuss a range of theoretical and practical issues that are as yet unsolved in terms of their importance and their effect on performance for different system implementations.},
	number = {3},
	urldate = {2014-09-08},
	journal = {Technometrics},
	author = {Juang, B. H. and Rabiner, L. R.},
	month = aug,
	year = {1991},
	pages = {251--272},
	file = {Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/6V7GI6J5/00401706.1991.html:text/html}
}

@inproceedings{bergquist_interactive_2009,
	title = {Interactive object recognition using proprioceptive feedback},
	url = {http://www.researchgate.net/publication/228397666_Interactive_object_recognition_using_proprioceptive_feedback/file/3deec5284ee9314268.pdf},
	urldate = {2015-01-13},
	booktitle = {Proceedings of the 2009 {IROS} Workshop: Semantic Perception for Robot Manipulation, St. Louis, {MO}},
	author = {Bergquist, Taylor and Schenck, Connor and Ohiri, Ugonna and Sinapov, Jivko and Griffith, Shane and Stoytchev, Alexander},
	year = {2009},
	note = {00019},
	file = {0deec5284ee9314268000000.pdf:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/JATMPUKW/0deec5284ee9314268000000.pdf:application/pdf}
}

@inproceedings{nakamura_multimodal_2007,
	title = {Multimodal object categorization by a robot},
	doi = {10.1109/IROS.2007.4399634},
	abstract = {In this paper unsupervised object categorization by robots is examined. We propose an unsupervised multimodal categorization based on audio-visual and haptic information. The robot uses its physical embodiment to grasp and observe an object from various view points as well as listen to the sound during the observation. The proposed categorization method is an extension of probabilistic latent semantic analysis({pLSA}), which is a statistical technique. At the same time the proposed method provides a probabilistic framework for inferring the object property from limited observations. Validity of the proposed method is shown through some experimental results.},
	booktitle = {{IEEE}/{RSJ} International Conference on Intelligent Robots and Systems, 2007. {IROS} 2007},
	author = {Nakamura, T. and Nagai, Takayuki and Iwahashi, N.},
	month = oct,
	year = {2007},
	note = {00042},
	keywords = {audio-visual, audio-visual systems, Grasping, haptic information, haptic interfaces, intelligent robots, Knowledge engineering, multimodal, multimodal object categorization, Natural languages, Notice of Violation, object categorization, object detection, Object recognition, {pLSA}, probabilistic Latent Semantic Analysis({pLSA}), probability, robot, robot vision, Training data, unsupervised learning, unsupervised object categorization, {USA} Councils},
	pages = {2415--2420},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/NXQUCME7/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/PI772U3D/Nakamura et al. - 2007 - Multimodal object categorization by a robot.pdf:application/pdf}
}

@inproceedings{attamimi_integration_2014,
	title = {Integration of various concepts and grounding of word meanings using multi-layered multimodal {LDA} for sentence generation},
	doi = {10.1109/IROS.2014.6942858},
	abstract = {In the field of intelligent robotics, object handling by robots can be achieved by capturing not only the object concept through object categorization, but also other concepts (e.g., the movement while using the object), as well as the relationship between concepts. Moreover, capturing the concepts of places and people is also necessary to enable the robot to gain real-world understanding. In this study, we propose multi-layered multimodal latent Dirichlet allocation ({mMLDA}) to realize the formation of various concepts, and the integration of those concepts, by robots. Because concept formation and integration can be conducted by {mMLDA}, the formation of each concept affects others, resulting in a more appropriate formation. Another issue to be addressed in this paper is the language acquisition by the robots. We propose a method to infer which words are originally connected to a concept using mutual information between words and concepts. Moreover, the order of concepts in teaching utterances can be learned using a simple Markov model, which corresponds to grammar. This grammar can be used to generate sentences that represent the observed information. We report the results of experiments to evaluate the effectiveness of the proposed method.},
	booktitle = {2014 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems ({IROS} 2014)},
	author = {Attamimi, M. and Fadlil, M. and Abe, K. and Nakamura, T. and Funakoshi, K. and Nagai, T.},
	month = sep,
	year = {2014},
	note = {00000},
	keywords = {Education, Grammar, intelligent robotics, intelligent robots, Markov processes, Medical services, {mMLDA}, multilayered multimodal latent Dirichlet allocation, multilayered multimodal {LDA}, object categorization, object handling, robot language acquisition, Robots, sentence generation, simple Markov model, Stethoscope, teaching utterances, Vectors, Visualization, word meanings},
	pages = {2194--2201},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/D53XSHB5/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/3FQA4JE6/Attamimi et al. - 2014 - Integration of various concepts and grounding of w.pdf:application/pdf}
}

@article{sivic_discovering_2005,
	title = {Discovering object categories in image collections},
	url = {http://dspace.mit.edu/handle/1721.1/30525},
	abstract = {Given a set of images containing multiple object categories,we seek to discover those categories and their image locations withoutsupervision.  We achieve this using generative modelsfrom the statistical text literature: probabilistic Latent {SemanticAnalysis} ({pLSA}), and Latent Dirichlet Allocation ({LDA}). In text analysisthese are used to discover topics in a corpus using the bag-of-wordsdocument representation. Here we discover topics as object categories, sothat an image containing instances of several categories is modelled as amixture of topics.The models are applied to images by using avisual analogue of a word, formed by vector quantizing {SIFT} like regiondescriptors.  We investigate a set of increasingly demanding scenarios,starting with image sets containing only two object categories through tosets containing multiple categories (including airplanes, cars, faces,motorbikes, spotted cats) and background clutter. The object categoriessample both intra-class and scale variation, and both the categories andtheir approximate spatial layout are found without supervision.We also demonstrate classification of unseen images and images containingmultiple objects. Performance of the proposed unsupervised method is compared tothe semi-supervised approach of Fergus et al.},
	language = {en\_US},
	urldate = {2015-01-13},
	author = {Sivic, Josef and Russell, Bryan C. and Efros, Alexei A. and Zisserman, Andrew and Freeman, William T.},
	month = feb,
	year = {2005},
	note = {00431},
	file = {MIT-CSAIL-TR-2005-012.pdf:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/8D8P7VWF/MIT-CSAIL-TR-2005-012.pdf:application/pdf;Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/M76GK6IV/30525.html:text/html}
}

@article{mikolajczyk_scale_2004,
	title = {Scale \& Affine Invariant Interest Point Detectors},
	volume = {60},
	issn = {0920-5691, 1573-1405},
	url = {http://link.springer.com/article/10.1023/B%3AVISI.0000027790.02288.f2},
	doi = {10.1023/B:VISI.0000027790.02288.f2},
	abstract = {In this paper we propose a novel approach for detecting interest points invariant to scale and affine transformations. Our scale and affine invariant detectors are based on the following recent results: (1) Interest points extracted with the Harris detector can be adapted to affine transformations and give repeatable results (geometrically stable). (2) The characteristic scale of a local structure is indicated by a local extremum over scale of normalized derivatives (the Laplacian). (3) The affine shape of a point neighborhood is estimated based on the second moment matrix. Our scale invariant detector computes a multi-scale representation for the Harris interest point detector and then selects points at which a local measure (the Laplacian) is maximal over scales. This provides a set of distinctive points which are invariant to scale, rotation and translation as well as robust to illumination changes and limited changes of viewpoint. The characteristic scale determines a scale invariant region for each point. We extend the scale invariant detector to affine invariance by estimating the affine shape of a point neighborhood. An iterative algorithm modifies location, scale and neighborhood of each point and converges to affine invariant points. This method can deal with significant affine transformations including large scale changes. The characteristic scale and the affine shape of neighborhood determine an affine invariant region for each point. We present a comparative evaluation of different detectors and show that our approach provides better results than existing methods. The performance of our detector is also confirmed by excellent matching results; the image is described by a set of scale/affine invariant descriptors computed on the regions associated with our points.},
	language = {en},
	number = {1},
	urldate = {2015-01-13},
	journal = {International Journal of Computer Vision},
	author = {Mikolajczyk, Krystian and Schmid, Cordelia},
	month = oct,
	year = {2004},
	note = {03231},
	keywords = {affine invariance, Artificial Intelligence (incl. Robotics), Automation and Robotics, Computer Imaging, Graphics and Computer Vision, image processing, interest points, local features, matching, recognition, scale invariance},
	pages = {63--86},
	file = {Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/JFQUGF9W/Mikolajczyk and Schmid - 2004 - Scale & Affine Invariant Interest Point Detectors.pdf:application/pdf;Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/JGGJEI6X/BVISI.0000027790.02288.html:text/html}
}

@book{rabiner_fundamentals_1993,
	address = {Englewood Cliffs, N.J.},
	title = {Fundamentals of speech recognition},
	isbn = {0130151572 9780130151575},
	language = {English},
	publisher = {{PTR} Prentice Hall},
	author = {Rabiner, , Lawrence R. and Juang, B. H.},
	year = {1993},
	note = {09095}
}

@book{grauman_visual_2011,
	address = {[San Rafael, Calif.]},
	title = {Visual object recognition},
	isbn = {1598299689 1598299697 9781598299687 9781598299694},
	language = {English},
	publisher = {Morgan \& Claypool},
	author = {Grauman, Kristen and Leibe, Bastian},
	year = {2011}
}

@inproceedings{dalal_histograms_2005,
	title = {Histograms of oriented gradients for human detection},
	volume = {1},
	doi = {10.1109/CVPR.2005.177},
	abstract = {We study the question of feature sets for robust visual object recognition; adopting linear {SVM} based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient ({HOG}) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original {MIT} pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.},
	booktitle = {{IEEE} Computer Society Conference on Computer Vision and Pattern Recognition, 2005. {CVPR} 2005},
	author = {Dalal, N. and Triggs, B.},
	month = jun,
	year = {2005},
	note = {09991},
	keywords = {coarse spatial binning, contrast normalization, edge based descriptors, feature extraction, fine orientation binning, fine-scale gradients, gradient based descriptors, gradient methods, High performance computing, Histograms, histograms of oriented gradients, human detection, Humans, Image databases, Image edge detection, linear {SVM}, object detection, Object recognition, overlapping descriptor, pedestrian database, Robustness, robust visual object recognition, Support vector machines, Testing},
	pages = {886--893 vol. 1},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/4MUERQ8B/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/9BXDARVW/Dalal and Triggs - 2005 - Histograms of oriented gradients for human detecti.pdf:application/pdf}
}

@inproceedings{viola_rapid_2001,
	title = {Rapid object detection using a boosted cascade of simple features},
	volume = {1},
	doi = {10.1109/CVPR.2001.990517},
	abstract = {This paper describes a machine learning approach for visual object detection which is capable of processing images extremely rapidly and achieving high detection rates. This work is distinguished by three key contributions. The first is the introduction of a new image representation called the "integral image" which allows the features used by our detector to be computed very quickly. The second is a learning algorithm, based on {AdaBoost}, which selects a small number of critical visual features from a larger set and yields extremely efficient classifiers. The third contribution is a method for combining increasingly more complex classifiers in a "cascade" which allows background regions of the image to be quickly discarded while spending more computation on promising object-like regions. The cascade can be viewed as an object specific focus-of-attention mechanism which unlike previous approaches provides statistical guarantees that discarded regions are unlikely to contain the object of interest. In the domain of face detection the system yields detection rates comparable to the best previous systems. Used in real-time applications, the detector runs at 15 frames per second without resorting to image differencing or skin color detection.},
	booktitle = {Proceedings of the 2001 {IEEE} Computer Society Conference on Computer Vision and Pattern Recognition, 2001. {CVPR} 2001},
	author = {Viola, P. and Jones, M.},
	year = {2001},
	note = {10295},
	keywords = {{AdaBoost}, background regions, boosted simple feature cascade, classifiers, Detectors, face detection, feature extraction, Filters, Focusing, image classification, image processing, image representation, integral image, learning (artificial intelligence), Machine learning, object detection, object specific focus-of-attention mechanism, Pixel, rapid object detection, real-time applications, Robustness, Skin, statistical guarantees, visual object detection},
	pages = {I--511--I--518 vol.1},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/7F4FPXN3/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/3NHD4CNJ/Viola and Jones - 2001 - Rapid object detection using a boosted cascade of .pdf:application/pdf}
}

@inproceedings{hofmann_probabilistic_1999,
	address = {San Francisco, {CA}, {USA}},
	series = {{UAI}'99},
	title = {Probabilistic Latent Semantic Analysis},
	isbn = {1-55860-614-9},
	url = {http://dl.acm.org/citation.cfm?id=2073796.2073829},
	abstract = {Probabilistic Latent Semantic Analysis is a novel statistical technique for the analysis of two-mode and co-occurrence data, which has applications in information retrieval and filtering, natural language processing, machine learning from text, and in related areas. Compared to standard Latent Semantic Analysis which stems from linear algebra and performs a Singular Value Decomposition of co-occurrence tables, the proposed method is based on a mixture decomposition derived from a latent class model. This results in a more principled approach which has a solid foundation in statistics. In order to avoid overfitting, we propose a widely applicable generalization of maximum likelihood model fitting by tempered {EM}. Our approach yields substantial and consistent improvements over Latent Semantic Analysis in a number of experiments.},
	urldate = {2015-02-11},
	booktitle = {Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Hofmann, Thomas},
	year = {1999},
	note = {01638},
	pages = {289--296},
	file = {ACM Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/MBFQC8Q2/Hofmann - 1999 - Probabilistic Latent Semantic Analysis.pdf:application/pdf}
}