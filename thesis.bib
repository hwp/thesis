
@inproceedings{lowe_object_1999,
	title = {Object recognition from local scale-invariant features},
	volume = {2},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=790410},
	urldate = {2013-01-15},
	booktitle = {Computer {Vision}, 1999. {The} {Proceedings} of the {Seventh} {IEEE} {International} {Conference} on},
	author = {Lowe, D. G.},
	year = {1999},
	note = {07873},
	pages = {1150--1157},
	file = {00790410.pdf:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/DKIH3U5W/00790410.pdf:application/pdf}
}

@inproceedings{sinapov_object_2011,
	title = {Object category recognition by a humanoid robot using behavior-grounded relational learning},
	doi = {10.1109/ICRA.2011.5980417},
	abstract = {The ability to form and recognize object categories is fundamental to human intelligence. This paper proposes a behavior-grounded relational classification model that allows a robot to recognize the categories of household objects. In the proposed approach, the robot initially explores the objects by applying five exploratory behaviors (lift, shake, drop, crush and push) on them while recording the proprioceptive and auditory sensory feedback produced by each interaction. The sensorimotor data is used to estimate multiple measures of similarity between the objects, each corresponding to a specific coupling between an exploratory behavior and a sensory modality. A graph-based recognition model is trained by extracting features from the estimated similarity relations, allowing the robot to recognize the category memberships of a novel object based on the object's similarity to the set of familiar objects. The framework was evaluated on an upper-torso humanoid robot with two large sets of household objects. The results show that the robot's model is able to recognize complex object categories (e.g., metal objects, empty bottles, etc.) significantly better than chance.},
	booktitle = {2011 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Sinapov, J. and Stoytchev, A.},
	year = {2011},
	note = {00018},
	keywords = {auditory sensory feedback, behavior-grounded relational learning, Context, domestic appliances, feature extraction, feedback, graph-based recognition model, household object, human intelligence, humanoid robots, image classification, Joints, learning (artificial intelligence), Metals, mobile robots, object category recognition, Object recognition, pattern matching, proprioceptive sensory feedback, Robot sensing systems, robot vision, sensorimotor data, sensory aids, similarity measure, Support vector machines, upper-torso humanoid robot},
	pages = {184--190},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/RDIIHAAC/abs_all.html:text/html;IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/AMA5FVKB/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/5KTZ9AES/Sinapov and Stoytchev - 2011 - Object category recognition by a humanoid robot us.pdf:application/pdf;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/HKCJS6NZ/Sinapov and Stoytchev - 2011 - Object category recognition by a humanoid robot us.pdf:application/pdf}
}

@inproceedings{viola_rapid_2001,
	title = {Rapid object detection using a boosted cascade of simple features},
	volume = {1},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=990517},
	urldate = {2013-01-23},
	booktitle = {Computer {Vision} and {Pattern} {Recognition}, 2001. {CVPR} 2001. {Proceedings} of the 2001 {IEEE} {Computer} {Society} {Conference} on},
	author = {Viola, P. and Jones, M.},
	year = {2001},
	keywords = {AdaBoost, background regions, boosted simple feature cascade, classifiers, Detectors, face detection, feature extraction, Filters, Focusing, image classification, image processing, image representation, integral image, learning (artificial intelligence), Machine learning, object detection, object specific focus-of-attention mechanism, Pixel, rapid object detection, real-time applications, Robustness, Skin, statistical guarantees, visual object detection},
	pages = {I--511},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/7F4FPXN3/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/3NHD4CNJ/Viola and Jones - 2001 - Rapid object detection using a boosted cascade of .pdf:application/pdf;violaJones_CVPR2001.pdf:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/FEE4XFEK/violaJones_CVPR2001.pdf:application/pdf}
}

@article{lowe_distinctive_2004,
	title = {Distinctive {Image} {Features} from {Scale}-{Invariant} {Keypoints}},
	volume = {60},
	issn = {0920-5691, 1573-1405},
	url = {http://link.springer.com/article/10.1023/B%3AVISI.0000029664.99615.94},
	doi = {10.1023/B:VISI.0000029664.99615.94},
	abstract = {This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.},
	language = {en},
	number = {2},
	urldate = {2013-08-29},
	journal = {International Journal of Computer Vision},
	author = {Lowe, David G.},
	month = nov,
	year = {2004},
	note = {21760},
	keywords = {Artificial Intelligence (incl. Robotics), Automation and Robotics, Computer Imaging, Graphics and Computer Vision, image matching, image processing, invariant features, Object recognition, scale invariance},
	pages = {91--110},
	file = {Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/SM44TSKZ/Lowe - 2004 - Distinctive Image Features from Scale-Invariant Ke.pdf:application/pdf;Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/ZN29JE27/BVISI.0000029664.99615.html:text/html}
}

@inproceedings{csurka_visual_2004,
	title = {Visual categorization with bags of keypoints},
	volume = {1},
	url = {http://217.109.185.161/layout/set/print/content/download/20785/148346/file/2004_010.pdf},
	urldate = {2013-08-28},
	booktitle = {Workshop on statistical learning in computer vision, {ECCV}},
	author = {Csurka, Gabriella and Dance, Christopher and Fan, Lixin and Willamowski, Jutta and Bray, Cédric},
	year = {2004},
	note = {02136},
	pages = {22},
	file = {2004_010.pdf:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/MEIFIHD3/2004_010.pdf:application/pdf;2004_010.pdf:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/87GRBQTR/2004_010.pdf:application/pdf}
}

@inproceedings{sinapov_interactive_2009,
	title = {Interactive learning of the acoustic properties of household objects},
	doi = {10.1109/ROBOT.2009.5152802},
	abstract = {Human beings can perceive object properties such as size, weight, and material type based solely on the sounds that the objects make when an action is performed on them. In order to be successful, the household robots of the near future must also be capable of learning and reasoning about the acoustic properties of everyday objects. Such an ability would allow a robot to detect and classify various interactions with objects that occur outside of the robot's field of view. This paper presents a framework that allows a robot to infer the object and the type of behavioral interaction performed with it from the sounds generated by the object during the interaction. The framework is evaluated on a 7-d.o.f. Barrett WAM robot which performs grasping, shaking, dropping, pushing and tapping behaviors on 36 different household objects. The results show that the robot can learn models that can be used to recognize objects (and behaviors performed on objects) from the sounds generated during the interaction. In addition, the robot can use the learned models to estimate the similarity between two objects in terms of their acoustic properties.},
	booktitle = {{IEEE} {International} {Conference} on {Robotics} and {Automation}, 2009. {ICRA} '09},
	author = {Sinapov, J. and Wiemer, M. and Stoytchev, A.},
	month = may,
	year = {2009},
	keywords = {Acoustic materials, acoustic properties, Acoustic signal detection, Barrett WAM robot, household objects, household robots, Human robot interaction, Information resources, interactive learning, Laboratories, learning (artificial intelligence), manipulators, microphones, object detection, reasoning, Robotics and automation, Robot sensing systems},
	pages = {2518--2524},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/GCWIKXJM/abs_all.html:text/html;IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/3M2MIKFU/abs_all.html:text/html;IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/ATR74864/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/TJEHDRKH/Sinapov et al. - 2009 - Interactive learning of the acoustic properties of.pdf:application/pdf;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/7K89EGPT/Sinapov et al. - 2009 - Interactive learning of the acoustic properties of.pdf:application/pdf;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/ADWWCQHC/Sinapov et al. - 2009 - Interactive learning of the acoustic properties of.pdf:application/pdf}
}

@inproceedings{dalal_histograms_2005,
	title = {Histograms of oriented gradients for human detection},
	volume = {1},
	doi = {10.1109/CVPR.2005.177},
	abstract = {We study the question of feature sets for robust visual object recognition; adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of histograms of oriented gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.},
	booktitle = {{IEEE} {Computer} {Society} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}, 2005. {CVPR} 2005},
	author = {Dalal, N. and Triggs, B.},
	year = {2005},
	note = {06787},
	keywords = {coarse spatial binning, contrast normalization, edge based descriptors, feature extraction, fine orientation binning, fine-scale gradients, gradient based descriptors, gradient methods, High performance computing, Histograms, histograms of oriented gradients, human detection, Humans, Image databases, Image edge detection, linear SVM, object detection, Object recognition, overlapping descriptor, pedestrian database, Robustness, robust visual object recognition, Support vector machines, Testing},
	pages = {886--893 vol. 1},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/XQMDBG4M/abs_all.html:text/html;IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/4MUERQ8B/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/T4PDHF7W/Dalal and Triggs - 2005 - Histograms of oriented gradients for human detecti.pdf:application/pdf;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/9BXDARVW/Dalal and Triggs - 2005 - Histograms of oriented gradients for human detecti.pdf:application/pdf}
}

@techreport{heinzel_spectrum_2002,
	title = {Spectrum and spectral density estimation by the {Discrete} {Fourier} transform ({DFT}), including a comprehensive list of window functions and some new flat-top windows},
	url = {http://helio.estec.esa.int/SP/LISAPATHFINDER/docs/Data_Analysis/GH_FFT.pdf},
	urldate = {2014-03-26},
	institution = {Max Planck Institute},
	author = {Heinzel, Gerhard and Rüdiger, A. and Schilling, Roland},
	year = {2002},
	note = {00000},
	pages = {122},
	file = {GH_FFT.pdf:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/B6IB6R5W/GH_FFT.pdf:application/pdf}
}

@article{needleman_general_1970,
	title = {A general method applicable to the search for similarities in the amino acid sequence of two proteins},
	volume = {48},
	issn = {0022-2836},
	url = {http://www.sciencedirect.com/science/article/pii/0022283670900574},
	doi = {10.1016/0022-2836(70)90057-4},
	abstract = {A computer adaptable method for finding similarities in the amino acid sequences of two proteins has been developed. From these findings it is possible to determine whether significant homology exists between the proteins. This information is used to trace their possible evolutionary development.

The maximum match is a number dependent upon the similarity of the sequences. One of its definitions is the largest number of amino acids of one protein that can be matched with those of a second protein allowing for all possible interruptions in either of the sequences. While the interruptions give rise to a very large number of comparisons, the method efficiently excludes from consideration those comparisons that cannot contribute to the maximum match.

Comparisons are made from the smallest unit of significance, a pair of amino acids, one from each protein. All possible pairs are represented by a two-dimensional array, and all possible comparisons are represented by pathways through the array. For this maximum match only certain of the possible pathways must be evaluated. A numerical value, one in this case, is assigned to every cell in the array representing like amino acids. The maximum match is the largest number that would result from summing the cell values of every pathway.},
	number = {3},
	urldate = {2015-02-13},
	journal = {Journal of Molecular Biology},
	author = {Needleman, Saul B. and Wunsch, Christian D.},
	month = mar,
	year = {1970},
	note = {09063},
	pages = {443--453},
	file = {ScienceDirect Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/SG9T6XCC/Needleman and Wunsch - 1970 - A general method applicable to the search for simi.pdf:application/pdf;ScienceDirect Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/NABHAM33/0022283670900574.html:text/html}
}

@article{cohen_coefficient_1960,
	title = {A coefficient of agreement for nominal scales},
	volume = {20},
	copyright = {(c) 2012 APA, all rights reserved},
	issn = {1552-3888(Electronic);0013-1644(Print)},
	doi = {10.1177/001316446002000104},
	abstract = {"A coefficient of interjudge agreement for nominal scales, K = (Po - Pc)/(1 - Pc), is presented. It is directly interpretable as the proportion of joint judgments in which there is agreement, after chance agreement is excluded… . The maximum value which k can take for any given problem is given, and the implications of this value to the question of agreement discussed." Standard error and techniques for estimation and hypothesis testing are presented.},
	journal = {Educational and Psychological Measurement},
	author = {Cohen, Jacob},
	year = {1960},
	note = {00003},
	pages = {37--46},
	file = {APA PsycNET Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/RNU9I8KR/index.html:text/html;Cohen_1960.pdf:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/ZXHFWF9E/Cohen_1960.pdf:application/pdf}
}

@article{juang_hidden_1991,
	title = {Hidden {Markov} {Models} for {Speech} {Recognition}},
	volume = {33},
	issn = {0040-1706},
	url = {http://www.tandfonline.com/doi/abs/10.1080/00401706.1991.10484833},
	doi = {10.1080/00401706.1991.10484833},
	abstract = {The use of hidden Markov models for speech recognition has become predominant in the last several years, as evidenced by the number of published papers and talks at major speech conferences. The reasons this method has become so popular are the inherent statistical (mathematically precise) framework; the ease and availability of training algorithms for cstimating the parameters of the models from finite training sets of speech data; the flexibility of the resulting recognition system in which one can easily change the size, type, or architecture of the models to suit particular words, sounds, and so forth; and the ease of implementation of the overall recognition system. In this expository article, we address the role of statistical methods in this powerful technology as applied to speech recognition and discuss a range of theoretical and practical issues that are as yet unsolved in terms of their importance and their effect on performance for different system implementations.},
	number = {3},
	urldate = {2014-09-08},
	journal = {Technometrics},
	author = {Juang, B. H. and Rabiner, L. R.},
	month = aug,
	year = {1991},
	pages = {251--272},
	file = {Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/6V7GI6J5/00401706.1991.html:text/html}
}

@inproceedings{bergquist_interactive_2009,
	title = {Interactive object recognition using proprioceptive feedback},
	url = {http://www.researchgate.net/publication/228397666_Interactive_object_recognition_using_proprioceptive_feedback/file/3deec5284ee9314268.pdf},
	urldate = {2015-01-13},
	booktitle = {Proceedings of the 2009 {IROS} {Workshop}: {Semantic} {Perception} for {Robot} {Manipulation}, {St}. {Louis}, {MO}},
	author = {Bergquist, Taylor and Schenck, Connor and Ohiri, Ugonna and Sinapov, Jivko and Griffith, Shane and Stoytchev, Alexander},
	year = {2009},
	note = {00019},
	file = {0deec5284ee9314268000000.pdf:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/JATMPUKW/0deec5284ee9314268000000.pdf:application/pdf}
}

@inproceedings{nakamura_multimodal_2007,
	title = {Multimodal object categorization by a robot},
	doi = {10.1109/IROS.2007.4399634},
	abstract = {In this paper unsupervised object categorization by robots is examined. We propose an unsupervised multimodal categorization based on audio-visual and haptic information. The robot uses its physical embodiment to grasp and observe an object from various view points as well as listen to the sound during the observation. The proposed categorization method is an extension of probabilistic latent semantic analysis(pLSA), which is a statistical technique. At the same time the proposed method provides a probabilistic framework for inferring the object property from limited observations. Validity of the proposed method is shown through some experimental results.},
	booktitle = {{IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems}, 2007. {IROS} 2007},
	author = {Nakamura, T. and Nagai, Takayuki and Iwahashi, N.},
	month = oct,
	year = {2007},
	note = {00042},
	keywords = {audio-visual, audio-visual systems, Grasping, haptic information, haptic interfaces, intelligent robots, Knowledge engineering, multimodal, multimodal object categorization, Natural languages, Notice of Violation, object categorization, object detection, Object recognition, pLSA, probabilistic Latent Semantic Analysis(pLSA), probability, robot, robot vision, Training data, unsupervised learning, unsupervised object categorization, USA Councils},
	pages = {2415--2420},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/NXQUCME7/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/PI772U3D/Nakamura et al. - 2007 - Multimodal object categorization by a robot.pdf:application/pdf}
}

@inproceedings{attamimi_integration_2014,
	title = {Integration of various concepts and grounding of word meanings using multi-layered multimodal {LDA} for sentence generation},
	doi = {10.1109/IROS.2014.6942858},
	abstract = {In the field of intelligent robotics, object handling by robots can be achieved by capturing not only the object concept through object categorization, but also other concepts (e.g., the movement while using the object), as well as the relationship between concepts. Moreover, capturing the concepts of places and people is also necessary to enable the robot to gain real-world understanding. In this study, we propose multi-layered multimodal latent Dirichlet allocation (mMLDA) to realize the formation of various concepts, and the integration of those concepts, by robots. Because concept formation and integration can be conducted by mMLDA, the formation of each concept affects others, resulting in a more appropriate formation. Another issue to be addressed in this paper is the language acquisition by the robots. We propose a method to infer which words are originally connected to a concept using mutual information between words and concepts. Moreover, the order of concepts in teaching utterances can be learned using a simple Markov model, which corresponds to grammar. This grammar can be used to generate sentences that represent the observed information. We report the results of experiments to evaluate the effectiveness of the proposed method.},
	booktitle = {2014 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS} 2014)},
	author = {Attamimi, M. and Fadlil, M. and Abe, K. and Nakamura, T. and Funakoshi, K. and Nagai, T.},
	month = sep,
	year = {2014},
	note = {00000},
	keywords = {Education, Grammar, intelligent robotics, intelligent robots, Markov processes, Medical services, mMLDA, multilayered multimodal latent Dirichlet allocation, multilayered multimodal LDA, object categorization, object handling, robot language acquisition, Robots, sentence generation, simple Markov model, Stethoscope, teaching utterances, Vectors, Visualization, word meanings},
	pages = {2194--2201},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/D53XSHB5/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/3FQA4JE6/Attamimi et al. - 2014 - Integration of various concepts and grounding of w.pdf:application/pdf}
}

@article{sivic_discovering_2005,
	title = {Discovering object categories in image collections},
	url = {http://dspace.mit.edu/handle/1721.1/30525},
	abstract = {Given a set of images containing multiple object categories,we seek to discover those categories and their image locations withoutsupervision.  We achieve this using generative modelsfrom the statistical text literature: probabilistic Latent SemanticAnalysis (pLSA), and Latent Dirichlet Allocation (LDA). In text analysisthese are used to discover topics in a corpus using the bag-of-wordsdocument representation. Here we discover topics as object categories, sothat an image containing instances of several categories is modelled as amixture of topics.The models are applied to images by using avisual analogue of a word, formed by vector quantizing SIFT like regiondescriptors.  We investigate a set of increasingly demanding scenarios,starting with image sets containing only two object categories through tosets containing multiple categories (including airplanes, cars, faces,motorbikes, spotted cats) and background clutter. The object categoriessample both intra-class and scale variation, and both the categories andtheir approximate spatial layout are found without supervision.We also demonstrate classification of unseen images and images containingmultiple objects. Performance of the proposed unsupervised method is compared tothe semi-supervised approach of Fergus et al.},
	language = {en\_US},
	urldate = {2015-01-13},
	author = {Sivic, Josef and Russell, Bryan C. and Efros, Alexei A. and Zisserman, Andrew and Freeman, William T.},
	month = feb,
	year = {2005},
	note = {00431},
	file = {MIT-CSAIL-TR-2005-012.pdf:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/8D8P7VWF/MIT-CSAIL-TR-2005-012.pdf:application/pdf;Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/M76GK6IV/30525.html:text/html}
}

@article{mikolajczyk_scale_2004,
	title = {Scale \& {Affine} {Invariant} {Interest} {Point} {Detectors}},
	volume = {60},
	issn = {0920-5691, 1573-1405},
	url = {http://link.springer.com/article/10.1023/B%3AVISI.0000027790.02288.f2},
	doi = {10.1023/B:VISI.0000027790.02288.f2},
	abstract = {In this paper we propose a novel approach for detecting interest points invariant to scale and affine transformations. Our scale and affine invariant detectors are based on the following recent results: (1) Interest points extracted with the Harris detector can be adapted to affine transformations and give repeatable results (geometrically stable). (2) The characteristic scale of a local structure is indicated by a local extremum over scale of normalized derivatives (the Laplacian). (3) The affine shape of a point neighborhood is estimated based on the second moment matrix. Our scale invariant detector computes a multi-scale representation for the Harris interest point detector and then selects points at which a local measure (the Laplacian) is maximal over scales. This provides a set of distinctive points which are invariant to scale, rotation and translation as well as robust to illumination changes and limited changes of viewpoint. The characteristic scale determines a scale invariant region for each point. We extend the scale invariant detector to affine invariance by estimating the affine shape of a point neighborhood. An iterative algorithm modifies location, scale and neighborhood of each point and converges to affine invariant points. This method can deal with significant affine transformations including large scale changes. The characteristic scale and the affine shape of neighborhood determine an affine invariant region for each point. We present a comparative evaluation of different detectors and show that our approach provides better results than existing methods. The performance of our detector is also confirmed by excellent matching results; the image is described by a set of scale/affine invariant descriptors computed on the regions associated with our points.},
	language = {en},
	number = {1},
	urldate = {2015-01-13},
	journal = {International Journal of Computer Vision},
	author = {Mikolajczyk, Krystian and Schmid, Cordelia},
	month = oct,
	year = {2004},
	note = {03231},
	keywords = {affine invariance, Artificial Intelligence (incl. Robotics), Automation and Robotics, Computer Imaging, Graphics and Computer Vision, image processing, interest points, local features, matching, recognition, scale invariance},
	pages = {63--86},
	file = {Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/JFQUGF9W/Mikolajczyk and Schmid - 2004 - Scale & Affine Invariant Interest Point Detectors.pdf:application/pdf;Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/JGGJEI6X/BVISI.0000027790.02288.html:text/html}
}

@book{rabiner_fundamentals_1993,
	address = {Englewood Cliffs, N.J.},
	title = {Fundamentals of speech recognition},
	isbn = {0130151572 9780130151575},
	language = {English},
	publisher = {PTR Prentice Hall},
	author = {Rabiner, , Lawrence R. and Juang, B. H.},
	year = {1993},
	note = {09235}
}

@book{grauman_visual_2011,
	address = {[San Rafael, Calif.]},
	title = {Visual object recognition},
	isbn = {1598299689 1598299697 9781598299687 9781598299694},
	language = {English},
	publisher = {Morgan \& Claypool},
	author = {Grauman, Kristen and Leibe, Bastian},
	year = {2011}
}

@inproceedings{hofmann_probabilistic_1999,
	address = {San Francisco, CA, USA},
	series = {{UAI}'99},
	title = {Probabilistic {Latent} {Semantic} {Analysis}},
	isbn = {1-55860-614-9},
	url = {http://dl.acm.org/citation.cfm?id=2073796.2073829},
	abstract = {Probabilistic Latent Semantic Analysis is a novel statistical technique for the analysis of two-mode and co-occurrence data, which has applications in information retrieval and filtering, natural language processing, machine learning from text, and in related areas. Compared to standard Latent Semantic Analysis which stems from linear algebra and performs a Singular Value Decomposition of co-occurrence tables, the proposed method is based on a mixture decomposition derived from a latent class model. This results in a more principled approach which has a solid foundation in statistics. In order to avoid overfitting, we propose a widely applicable generalization of maximum likelihood model fitting by tempered EM. Our approach yields substantial and consistent improvements over Latent Semantic Analysis in a number of experiments.},
	urldate = {2015-02-11},
	booktitle = {Proceedings of the {Fifteenth} {Conference} on {Uncertainty} in {Artificial} {Intelligence}},
	publisher = {Morgan Kaufmann Publishers Inc.},
	author = {Hofmann, Thomas},
	year = {1999},
	pages = {289--296},
	file = {ACM Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/SUQDCUGI/Hofmann - 1999 - Probabilistic Latent Semantic Analysis.pdf:application/pdf;ACM Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/MBFQC8Q2/Hofmann - 1999 - Probabilistic Latent Semantic Analysis.pdf:application/pdf}
}

@article{zheng_comparison_2001,
	title = {Comparison of different implementations of {MFCC}},
	volume = {16},
	issn = {1000-9000, 1860-4749},
	url = {http://link.springer.com/article/10.1007/BF02943243},
	doi = {10.1007/BF02943243},
	abstract = {The performance of the Mel-Frequency Cepstrum Coefficients (MFCC) may be affected by (1) the number of filters, (2) the shape of filters, (3) the way in which filters are spaced, and (4) the way in which the power spectrum is warped. In this paper, several comparison experiments are done to find a best implementation. The traditional MFCC calculation excludes the 0th coefficient for the reason that it is regarded as somewhat unreliable. According to the analysis and experiments, the authors find that it can be regarded as the generalized frequency band energy (FBE) and is hence useful, which results in the FBE-MFCC. The authors also propose a better analysis, namely the auto-regressive analysis, on the frame energy, which outperform its 1st and/or 2nd order differential derivatives. Experiments with the “863” Speech Database show that, compared with the traditional MFCC with its corresponding auto-regressive analysis coefficients, the FBE-MFCC and the frame energy with their corresponding auto-regressive analysis coefficients form the best combination, reducing the Chinese syllable error rate (CSER) by about 10\%, while the FBE-MFCC with the corresponding auto-regressive analysis coefficients reduces CSER by 2.5\%. Comparison experiments are also done with a quite casual Chinese speech database, named Chinese Annotated Spontaneous Speech (CASS) corpus. The FBE-MFCC can reduce the error rate by about 2.9\% on an average.},
	language = {en},
	number = {6},
	urldate = {2015-03-10},
	journal = {Journal of Computer Science and Technology},
	author = {Zheng, Fang and Zhang, Guoliang and Song, Zhanjiang},
	month = nov,
	year = {2001},
	keywords = {Artificial Intelligence (incl. Robotics), auto-regressive analysis, Computer Science, general, Data Structures, Cryptology and Information Theory, frequency band energy, generalized initial/final, Information Systems Applications (incl.Internet), MFCC, Software Engineering, Theory of Computation},
	pages = {582--589},
	file = {Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/TQ57NRVA/Zheng et al. - 2001 - Comparison of different implementations of MFCC.pdf:application/pdf;Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/82HUDUD4/10.html:text/html}
}

@article{lynott_modality_2009,
	title = {Modality exclusivity norms for 423 object properties},
	volume = {41},
	issn = {1554-351X, 1554-3528},
	url = {http://link.springer.com/article/10.3758/BRM.41.2.558},
	doi = {10.3758/BRM.41.2.558},
	abstract = {Recent work has shown that people routinely use perceptual information during language comprehension and conceptual processing, from single-word recognition to modality-switching costs in property verification. In investigating such links between perceptual and conceptual representations, the use of modality-specific stimuli plays a central role. To aid researchers working in this area, we provide a set of norms for 423 adjectives, each describing an object property, with mean ratings of how strongly that property is experienced through each of five perceptual modalities (visual, haptic, auditory, olfactory, and gustatory). The data set also contains estimates of modality exclusivity—that is, a measure of the extent to which a particular property may be considered unimodal (i.e., perceived through one sense alone). Although there already exists a number of sets of word and object norms, we provide the first set to categorize words describing object properties along the dimensions of the five perceptual modalities. We hope that the norms will be of use to researchers working at the interface between linguistic, conceptual, and perceptual systems. The modality exclusivity norms may be downloaded as supplemental materials for this article from brm.psychonomic-journals.org/ content/supplemental.},
	language = {en},
	number = {2},
	urldate = {2015-02-11},
	journal = {Behavior Research Methods},
	author = {Lynott, Dermot and Connell, Louise},
	month = may,
	year = {2009},
	note = {00048},
	keywords = {Cognitive Psychology},
	pages = {558--564},
	file = {Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/4IS4UVCV/Lynott and Connell - 2009 - Modality exclusivity norms for 423 object properti.pdf:application/pdf;Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/MI2JCJJH/10.3758BRM.41.2.html:text/html}
}

@article{takamuku_object_2008,
	title = {Object {Category} {Acquisition} by {Dynamic} {Touch}},
	volume = {22},
	issn = {0169-1864},
	url = {http://dx.doi.org/10.1163/156855308X324820},
	doi = {10.1163/156855308X324820},
	abstract = {The acquisition of object categories which underlie the human lexicon is a prerequisite for domestic robots to communicate with users in a human-like manner. The theory of J. J. Gibson inspires the approach to obtain shared categories through interaction with the shared environment, where explorative behaviors of infants play the role of obtaining distinctive features of objects to shape their categories. Although several existing studies have reproduced the exploratory behaviors of infants by robots to investigate their roles in acquiring such categories, those active categorization methods utilized static touches and the recognition tended to fail by changes of contact conditions. This paper introduces another possible approach to object categorization — object category acquisition by dynamic touch. Dynamic touch (e.g., shaking) provides the agent with the information of the whole object to enable quick and robust recognition. The amplitude spectrum of auditory data which humans obtain during shaking is found to be an effective feature for identifying the object categories of differing dynamics, e.g., rigid objects, paper materials and bottles of water, even though the objects within each category vary in size, shape, amount and contact conditions. Experimental results are given to show the validity of the proposed method and future issues are discussed.},
	number = {10},
	urldate = {2015-02-13},
	journal = {Advanced Robotics},
	author = {Takamuku, Shinya and Hosoda, Koh and Asada, Minoru},
	month = jan,
	year = {2008},
	note = {00017},
	pages = {1143--1154},
	file = {Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/GZB3FNIK/Takamuku et al. - 2008 - Object Category Acquisition by Dynamic Touch.pdf:application/pdf;Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/VSD9HKI5/156855308X324820.html:text/html}
}

@incollection{xu_hmm-based_2004,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{HMM}-{Based} {Audio} {Keyword} {Generation}},
	copyright = {©2005 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-23985-7, 978-3-540-30543-9},
	url = {http://link.springer.com/chapter/10.1007/978-3-540-30543-9_71},
	abstract = {With the exponential growth in the production creation of multimedia data, there is an increasing need for video semantic analysis. Audio, as a significant part of video, provides important cues to human perception when humans are browsing and understanding video contents. To detect semantic content by useful audio information, we introduce audio keywords which are sets of specific audio sounds related to semantic events. In our previous work, we designed a hierarchical Support Vector Machine (SVM) classifier for audio keyword identification. However, a weakness of our previous work is that audio signals are artificially segmented into 20 ms frames for frame-based SVM identification without any contextual information. In this paper, we propose a classification method based on Hidden Markov Modal (HMM) for audio keyword identification as an improved work instead of using hierarchical SVM classifier. Choosing HMM is motivated by the successful story of HMM in speech recognition. Unlike the frame-based SVM classification followed by major voting, our proposed HMM-based classifiers treat specific sound as a continuous time series data and employ hidden states transition to capture context information. In particular, we study how to find an effective HMM, i.e., determining topology, observation vectors and statistical parameters of HMM. We also compare different HMM structures with different hidden states, and adjust time series data with variable length. Experimental data includes 40 minutes basketball au-dio which comes from real-time sports games. Experimental results show that, for audio keyword generation, the proposed HMM-based method outperforms the previous hierarchical SVM.},
	language = {en},
	number = {3333},
	urldate = {2015-02-16},
	booktitle = {Advances in {Multimedia} {Information} {Processing} - {PCM} 2004},
	publisher = {Springer Berlin Heidelberg},
	author = {Xu, Min and Duan, Ling-Yu and Cai, Jianfei and Chia, Liang-Tien and Xu, Changsheng and Tian, Qi},
	editor = {Aizawa, Kiyoharu and Nakamura, Yuichi and Satoh, Shin’ichi},
	year = {2004},
	note = {00000},
	keywords = {Computer Communication Networks, Computer Graphics, Image Processing and Computer Vision, Information Storage and Retrieval, Information Systems Applications (incl.Internet), Multimedia Information Systems},
	pages = {566--574},
	file = {Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/DVAEZBPV/Xu et al. - 2004 - HMM-Based Audio Keyword Generation.pdf:application/pdf;Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/ZCX37E3E/978-3-540-30543-9_71.html:text/html}
}

@article{dempster_maximum_1977,
	title = {Maximum {Likelihood} from {Incomplete} {Data} via the {EM} {Algorithm}},
	volume = {39},
	copyright = {Copyright © 1977 Royal Statistical Society},
	issn = {0035-9246},
	url = {http://www.jstor.org/stable/2984875},
	abstract = {A broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. Theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. Many examples are sketched, including missing value situations, applications to grouped, censored or truncated data, finite mixture models, variance component estimation, hyperparameter estimation, iteratively reweighted least squares and factor analysis.},
	number = {1},
	urldate = {2015-02-25},
	journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
	author = {Dempster, A. P. and Laird, N. M. and Rubin, D. B.},
	month = jan,
	year = {1977},
	note = {40432},
	pages = {1--38},
	file = {JSTOR Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/CFQCSZXJ/Dempster et al. - 1977 - Maximum Likelihood from Incomplete Data via the EM.pdf:application/pdf}
}

@article{baker_dragon_1975,
	title = {The {DRAGON} system–{An} overview},
	volume = {23},
	issn = {0096-3518},
	doi = {10.1109/TASSP.1975.1162650},
	abstract = {This paper briefly describes the major features of the DRAGON speech understanding system. DRAGON makes systematic use of a general abstract model to represent each of the knowledge sources necessary for automatic recognition of continuous speech. The model–that of a probabilistic function of a Markov process–is very flexible and leads to features which allow DRAGON to function despite high error rates from individual knowledge sources. Repeated use of a simple abstract model produces a system which is simple in structure, but powerful in capabilities.},
	number = {1},
	journal = {IEEE Transactions on Acoustics, Speech and Signal Processing},
	author = {Baker, J.},
	month = feb,
	year = {1975},
	note = {00605},
	keywords = {Acoustic measurements, automatic speech recognition, Data mining, Error analysis, Markov processes, Power system modeling, Power system reliability, Random variables, Speech recognition, vocabulary},
	pages = {24--29},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/3Q5UDKCT/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/3N3WM4BM/Baker - 1975 - The DRAGON system–An overview.pdf:application/pdf}
}

@book{koski_hidden_2001,
	address = {Dordrecht; Boston; Norwell, MA},
	title = {Hidden {Markov} models for bioinformatics},
	isbn = {1402001355  9781402001352  1402001363 9781402001369},
	abstract = {The purpose of this book is to give a thorough and systematic introduction to probabilistic modeling in bioinformatics. The book contains a mathematically strict and extensive presentation of the kind of probabilistic models that have turned out to be useful in genome analysis. Questions of parametric inference, selection between model families, and various architectures are treated. Several examples are given of known architectures (e.g., profile HMM) used in genome analysis.},
	language = {English},
	publisher = {Kluwer Academic Publishers ; Distributed in North, Central and South America by Kluwer Academic Publishers},
	author = {Koski, Timo},
	year = {2001},
	note = {00201}
}

@article{thomas_hidden_2002,
	series = {Credit {Derivatives}},
	title = {A hidden {Markov} chain model for the term structure of bond credit risk spreads},
	volume = {11},
	issn = {1057-5219},
	url = {http://www.sciencedirect.com/science/article/pii/S1057521902000789},
	doi = {10.1016/S1057-5219(02)00078-9},
	abstract = {This paper provides a Markov chain model for the term structure and credit risk spreads of bond prices. It allows dependency between the stochastic process modeling the interest rate and the Markov chain process describing changes in the credit rating of the bonds by their mutual dependency on a hidden Markov chain, which can be thought of as describing the underlying economic conditions. The model also allows a new interpretation of risk premia used in previous approaches and also uses a linear programming approach to strip the bonds of their coupons in such a way as to guarantee there is no mispricing.},
	number = {3},
	urldate = {2015-03-03},
	journal = {International Review of Financial Analysis},
	author = {Thomas, Lyn C. and Allen, David E. and Morkel-Kingsbury, Nigel},
	year = {2002},
	note = {00029},
	pages = {311--329},
	file = {ScienceDirect Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/U3DX4CGW/Thomas et al. - 2002 - A hidden Markov chain model for the term structure.pdf:application/pdf;ScienceDirect Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/RND9ZZ8T/S1057521902000789.html:text/html}
}

@article{baum_maximization_1970,
	title = {A maximization technique occurring in the statistical analysis of probabilistic functions of {Markov} chains},
	url = {http://www.jstor.org/stable/2239727},
	urldate = {2015-03-03},
	journal = {The annals of mathematical statistics},
	author = {Baum, Leonard E. and Petrie, Ted and Soules, George and Weiss, Norman},
	year = {1970},
	note = {03588},
	pages = {164--171},
	file = {2239727.pdf:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/NVDA2FXC/2239727.pdf:application/pdf}
}

@article{forney_viterbi_1973,
	title = {The viterbi algorithm},
	volume = {61},
	issn = {0018-9219},
	doi = {10.1109/PROC.1973.9030},
	abstract = {The Viterbi algorithm (VA) is a recursive optimal solution to the problem of estimating the state sequence of a discrete-time finite-state Markov process observed in memoryless noise. Many problems in areas such as digital communications can be cast in this form. This paper gives a tutorial exposition of the algorithm and of how it is implemented and analyzed. Applications to date are reviewed. Increasing use of the algorithm in a widening variety of areas is foreseen.},
	number = {3},
	journal = {Proceedings of the IEEE},
	author = {Forney, G.D., Jr.},
	month = mar,
	year = {1973},
	note = {05035},
	keywords = {Algorithm design and analysis, Convolutional codes, Decoding, Digital communication, Helium, Markov processes, Recursive estimation, State estimation, Stochastic processes, Viterbi algorithm},
	pages = {268--278},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/3QNPBF8V/login.html:text/html}
}

@article{baum_statistical_1966,
	title = {Statistical inference for probabilistic functions of finite state {Markov} chains},
	url = {http://www.jstor.org/stable/2238772},
	urldate = {2015-03-03},
	journal = {The annals of mathematical statistics},
	author = {Baum, Leonard E. and Petrie, Ted},
	year = {1966},
	note = {01767},
	pages = {1554--1563}
}

@book{bhar_hidden_2004,
	title = {Hidden {Markov} {Models}: {Applications} to {Financial} {Economics}},
	isbn = {9781402078996},
	shorttitle = {Hidden {Markov} {Models}},
	abstract = {Markov chains have increasingly become useful way of capturing stochastic nature of many economic and financial variables. Although the hidden Markov processes have been widely employed for some time in many engineering applications e.g. speech recognition, its effectiveness has now been recognized in areas of social science research as well. The main aim of Hidden Markov Models: Applications to Financial Economics is to make such techniques available to more researchers in financial economics. As such we only cover the necessary theoretical aspects in each chapter while focusing on real life applications using contemporary data mainly from OECD group of countries. The underlying assumption here is that the researchers in financial economics would be familiar with such application although empirical techniques would be more traditional econometrics. Keeping the application level in a more familiar level, we focus on the methodology based on hidden Markov processes. This will, we believe, help the reader to develop more in-depth understanding of the modeling issues thereby benefiting their future research.},
	language = {en},
	publisher = {Springer Science \& Business Media},
	author = {Bhar, Ramaprasad and Hamori, Shigeyuki},
	month = jul,
	year = {2004},
	note = {00065},
	keywords = {Business \& Economics / Econometrics, Business \& Economics / Economics / General, Business \& Economics / Economics / Macroeconomics, Business \& Economics / Economics / Microeconomics, Business \& Economics / Finance, Business \& Economics / Finance / General, Business \& Economics / General, Business \& Economics / International / Economics, Business \& Economics / International / General, Business \& Economics / Public Finance}
}

@article{chen_off-line_1994,
	title = {Off-line handwritten word recognition using a hidden {Markov} model type stochastic network},
	volume = {16},
	issn = {0162-8828},
	doi = {10.1109/34.291449},
	abstract = {Because of large variations involved in handwritten words, the recognition problem is very difficult. Hidden Markov models (HMM) have been widely and successfully used in speech processing and recognition. Recently HMM has also been used with some success in recognizing handwritten words with presegmented letters. In this paper, a complete scheme for totally unconstrained handwritten word recognition based on a single contextual hidden Markov model type stochastic network is presented. Our scheme includes a morphology and heuristics based segmentation algorithm, a training algorithm that can adapt itself with the changing dictionary, and a modified Viterbi algorithm which searches for the (l+1)th globally best path based on the previous l best paths. Detailed experiments are carried out and successful recognition results are reported},
	number = {5},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Chen, Mou-Yen and Kundu, A. and Zhou, Jian},
	month = may,
	year = {1994},
	note = {00243},
	keywords = {character recognition, Handwriting recognition, heuristic programming, heuristics based segmentation algorithm, Hidden Markov models, hidden Markov model type stochastic network, image segmentation, mathematical morphology, morphology, off-line handwritten word recognition, Signal detection, speech processing, Speech recognition, Stochastic processes, text analysis, totally unconstrained handwritten word recognition, training algorithm, Viterbi algorithm, Writing},
	pages = {481--496},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/I6C4N799/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/5X4W3DWT/Chen et al. - 1994 - Off-line handwritten word recognition using a hidd.pdf:application/pdf}
}

@article{rabiner_tutorial_1989,
	title = {A tutorial on hidden {Markov} models and selected applications in speech recognition},
	volume = {77},
	issn = {0018-9219},
	doi = {10.1109/5.18626},
	abstract = {This tutorial provides an overview of the basic theory of hidden Markov models (HMMs) as originated by L.E. Baum and T. Petrie (1966) and gives practical details on methods of implementation of the theory along with a description of selected applications of the theory to distinct problems in speech recognition. Results from a number of original sources are combined to provide a single source of acquiring the background required to pursue further this area of research. The author first reviews the theory of discrete Markov chains and shows how the concept of hidden states, where the observation is a probabilistic function of the state, can be used effectively. The theory is illustrated with two simple examples, namely coin-tossing, and the classic balls-in-urns system. Three fundamental problems of HMMs are noted and several practical techniques for solving these problems are given. The various types of HMMs that have been studied, including ergodic as well as left-right models, are described},
	number = {2},
	journal = {Proceedings of the IEEE},
	author = {Rabiner, L.},
	month = feb,
	year = {1989},
	note = {20427},
	keywords = {balls-in-urns system, coin-tossing, discrete Markov chains, distortion, ergodic models, Hidden Markov models, hidden states, left-right models, Markov processes, Mathematical model, Multiple signal classification, probabilistic function, Signal processing, Speech recognition, Statistical analysis, Stochastic processes, Temperature measurement, Tutorial},
	pages = {257--286},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/ACCHT6EG/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/BRUFGRJF/Rabiner - 1989 - A tutorial on hidden Markov models and selected ap.pdf:application/pdf}
}

@article{bilmes_gentle_1998,
	title = {A gentle tutorial of the {EM} algorithm and its application to parameter estimation for {Gaussian} mixture and hidden {Markov} models},
	volume = {4},
	url = {http://lasa.epfl.ch/teaching/lectures/ML_Phd/Notes/GP-GMM.pdf},
	number = {510},
	urldate = {2015-03-07},
	journal = {International Computer Science Institute},
	author = {Bilmes, Jeff A.},
	year = {1998},
	note = {02156},
	pages = {126},
	file = {em.pdf:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/TXS7U5HF/em.pdf:application/pdf}
}

@article{davis_comparison_1980,
	title = {Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences},
	volume = {28},
	issn = {0096-3518},
	doi = {10.1109/TASSP.1980.1163420},
	abstract = {Several parametric representations of the acoustic signal were compared with regard to word recognition performance in a syllable-oriented continuous speech recognition system. The vocabulary included many phonetically similar monosyllabic words, therefore the emphasis was on the ability to retain phonetically significant acoustic information in the face of syntactic and duration variations. For each parameter set (based on a mel-frequency cepstrum, a linear frequency cepstrum, a linear prediction cepstrum, a linear prediction spectrum, or a set of reflection coefficients), word templates were generated using an efficient dynamic warping method, and test data were time registered with the templates. A set of ten mel-frequency cepstrum coefficients computed every 6.4 ms resulted in the best performance, namely 96.5 percent and 95.0 percent recognition with each of two speakers. The superior performance of the mel-frequency cepstrum coefficients may be attributed to the fact that they better represent the perceptually relevant aspects of the short-term speech spectrum.},
	number = {4},
	journal = {IEEE Transactions on Acoustics, Speech and Signal Processing},
	author = {Davis, S. and Mermelstein, P.},
	month = aug,
	year = {1980},
	keywords = {Acoustic measurements, Acoustic testing, Band pass filters, Cepstrum, Filtering, Laboratories, Loudspeakers, Nonlinear filters, Speech analysis, Speech recognition},
	pages = {357--366},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/R57SAXIJ/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/NEAJFDBK/Davis and Mermelstein - 1980 - Comparison of parametric representations for monos.pdf:application/pdf}
}

@article{oppenheim_frequency_2004,
	title = {From frequency to quefrency: a history of the cepstrum},
	volume = {21},
	issn = {1053-5888},
	shorttitle = {From frequency to quefrency},
	doi = {10.1109/MSP.2004.1328092},
	abstract = {The idea of the log spectrum or cepstral averaging has been useful in many applications such as audio processing, speech processing, speech recognition, and echo detection for the estimation and compensation of convolutional distortions. To suggest what prompted the invention of the term cepstrum, this article narrates the historical and mathematical background that led to its discovery. The computations of earlier simple echo representations have shown that the spectrum representation domain results does not belong in the frequency or time domain. Bogert et al. (1963) chose to refer to it as quefrency domain and later termed the spectrum of the log of a time waveform as the cepstrum. The article also recounts the analysis of Al Oppenheim in relation to the cepstrum. It was in his theory for nonlinear signal processing, referred to as homomorphic systems, that the realization of the characteristic system of homomorphic convolution was reminiscent of the cepstrum. To retain both the relationship to the work of Bogart et al. and the distinction, the term power cepstrum was eventually applied to the nonlinear mapping in homomorphic deconvolution . While most of the terms in the glossary have faded into the background, the term cepstrum has survived and has become part of the digital signal processing lexicon.},
	number = {5},
	journal = {IEEE Signal Processing Magazine},
	author = {Oppenheim, A.V. and Schafer, R.W.},
	month = sep,
	year = {2004},
	keywords = {cepstral analysis, Cepstrum, Convolution, convolutional distortions, Deconvolution, digital signal processing lexicon, Frequency, History, homomorphic systems, log spectrum, Nonlinear distortion, nonlinear signal processing, Signal processing, speech processing, Speech recognition, time waveform},
	pages = {95--106},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/UZR8U73F/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/FAS54XUQ/Oppenheim and Schafer - 2004 - From frequency to quefrency a history of the ceps.pdf:application/pdf}
}

@article{stevens_scale_1937,
	title = {A {Scale} for the {Measurement} of the {Psychological} {Magnitude} {Pitch}},
	volume = {8},
	issn = {0001-4966},
	url = {http://scitation.aip.org/content/asa/journal/jasa/8/3/10.1121/1.1915893},
	doi = {10.1121/1.1915893},
	abstract = {A subjective scale for the measurement of pitch was constructed from determinations of the half‐value of pitches at various frequencies. This scale differs from both the musical scale and the frequency scale, neither of which is subjective. Five observers fractionated tones of 10 different frequencies at a loudness level of 60 db. From these fractionations a numerical scale was constructed which is proportional to the perceived magnitude of subjective pitch. In numbering the scale the 1000‐cycle tone was assigned the pitch of 1000 subjective units (mels). The close agreement of the pitchscale with an integration of the differential thresholds (DL\&apos;s) shows that, unlike the DL\&apos;s for loudness, all DL\&apos;s for pitch are of uniform subjective magnitude. The agreement further implies that pitch and differential sensitivity to pitch are both rectilinear functions of extent on the basilar membrane. The correspondence of the pitchscale and the experimentally determined location of the resonant areas of the basilar membrane suggests that, in cutting a pitch in half, the observer adjusts the tone until it stimulates a position half‐way from the original locus to the apical end of the membrane. Measurement of the subjective size of musical intervals (such as octaves) in terms of the pitchscale shows that the intervals become larger as the frequency of the mid‐point of the interval increases (except in the two highest audible octaves). This result confirms earlier judgments as to the relative size of octaves in different parts of the frequency range.},
	number = {3},
	urldate = {2015-03-10},
	journal = {The Journal of the Acoustical Society of America},
	author = {Stevens, S. S. and Volkmann, J. and Newman, E. B.},
	month = jan,
	year = {1937},
	keywords = {Loudness, Music scales, Pitch},
	pages = {185--190},
	file = {Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/FF4V6JJX/Stevens et al. - 1937 - A Scale for the Measurement of the Psychological M.pdf:application/pdf;Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/6NKW4922/1.html:text/html}
}

@book{oshaughnessy_speech_1987,
	address = {Reading, Mass.},
	title = {Speech communication: human and machine},
	isbn = {0201165201 9780201165203},
	shorttitle = {Speech communication},
	language = {English},
	publisher = {Addison-Wesley Pub. Co.},
	author = {O'Shaughnessy, Douglas},
	year = {1987}
}

@incollection{mikolajczyk_affine_2002,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {An {Affine} {Invariant} {Interest} {Point} {Detector}},
	copyright = {©2002 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-43745-1, 978-3-540-47969-7},
	url = {http://link.springer.com/chapter/10.1007/3-540-47969-4_9},
	abstract = {This paper presents a novel approach for detecting affine invariant interest points. Our method can deal with significant affine transformations including large scale changes. Such transformations introduce significant changes in the point location as well as in the scale and the shape of the neighbourhood of an interest point. Our approach allows to solve for these problems simultaneously. It is based on three key ideas: 1) The second moment matrix computed in a point can be used to normalize a region in an affine invariant way (skew and stretch). 2) The scale of the local structure is indicated by local extrema of normalized derivatives over scale. 3) An affine-adapted Harris detector determines the location of interest points. A multi-scale version of this detector is used for initialization. An iterative algorithm then modifies location, scale and neighbourhood of each point and converges to affine invariant points. For matching and recognition, the image is characterized by a set of affine invariant points; the affine transformation associated with each point allows the computation of an affine invariant descriptor which is also invariant to affine illumination changes. A quantitative comparison of our detector with existing ones shows a significant improvement in the presence of large affine deformations. Experimental results for wide baseline matching show an excellent performance in the presence of large perspective transformations including significant scale changes. Results for recognition are very good for a database with more than 5000 images.},
	language = {en},
	number = {2350},
	urldate = {2015-03-11},
	booktitle = {Computer {Vision} — {ECCV} 2002},
	publisher = {Springer Berlin Heidelberg},
	author = {Mikolajczyk, Krystian and Schmid, Cordelia},
	editor = {Heyden, Anders and Sparr, Gunnar and Nielsen, Mads and Johansen, Peter},
	year = {2002},
	keywords = {Artificial Intelligence (incl. Robotics), Computer Graphics, Image features, Image Processing and Computer Vision, matching, Pattern Recognition, recognition},
	pages = {128--142},
	file = {Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/EAV7M7UC/Mikolajczyk and Schmid - 2002 - An Affine Invariant Interest Point Detector.pdf:application/pdf;Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/V6IP3N6F/3-540-47969-4_9.html:text/html}
}

@article{lindeberg_feature_1998,
	title = {Feature {Detection} with {Automatic} {Scale} {Selection}},
	volume = {30},
	issn = {0920-5691, 1573-1405},
	url = {http://link.springer.com/article/10.1023/A%3A1008045108935},
	doi = {10.1023/A:1008045108935},
	abstract = {The fact that objects in the world appear in different ways depending on the scale of observation has important implications if one aims at describing them. It shows that the notion of scale is of utmost importance when processing unknown measurement data by automatic methods. In their seminal works, Witkin (1983) and Koenderink (1984) proposed to approach this problem by representing image structures at different scales in a so-called scale-space representation. Traditional scale-space theory building on this work, however, does not address the problem of how to select local appropriate scales for further analysis. This article proposes a systematic methodology for dealing with this problem. A framework is presented for generating hypotheses about interesting scale levels in image data, based on a general principle stating that local extrema over scales of different combinations of γ-normalized derivatives are likely candidates to correspond to interesting structures. Specifically, it is shown how this idea can be used as a major mechanism in algorithms for automatic scale selection, which adapt the local scales of processing to the local image structure. Support for the proposed approach is given in terms of a general theoretical investigation of the behaviour of the scale selection method under rescalings of the input pattern and by integration with different types of early visual modules, including experiments on real-world and synthetic data. Support is also given by a detailed analysis of how different types of feature detectors perform when integrated with a scale selection mechanism and then applied to characteristic model patterns. Specifically, it is described in detail how the proposed methodology applies to the problems of blob detection, junction detection, edge detection, ridge detection and local frequency estimation. In many computer vision applications, the poor performance of the low-level vision modules constitutes a major bottleneck. It is argued that the inclusion of mechanisms for automatic scale selection is essential if we are to construct vision systems to automatically analyse complex unknown environments.},
	language = {en},
	number = {2},
	urldate = {2015-03-11},
	journal = {International Journal of Computer Vision},
	author = {Lindeberg, Tony},
	month = nov,
	year = {1998},
	keywords = {Artificial Intelligence (incl. Robotics), Automation and Robotics, blob detection, Computer Imaging, Graphics and Computer Vision, computer vision, corner detection, feature detection, frequency estimation, Gaussian derivative, image processing, multi-scale representation, normalized derivative, scale, scale selection, scale-space},
	pages = {79--116},
	file = {Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/53P3TMUH/Lindeberg - 1998 - Feature Detection with Automatic Scale Selection.pdf:application/pdf;Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/Z8B3CAU5/A1008045108935.html:text/html}
}

@article{matas_robust_2004,
	series = {British {Machine} {Vision} {Computing} 2002},
	title = {Robust wide-baseline stereo from maximally stable extremal regions},
	volume = {22},
	issn = {0262-8856},
	url = {http://www.sciencedirect.com/science/article/pii/S0262885604000435},
	doi = {10.1016/j.imavis.2004.02.006},
	abstract = {The wide-baseline stereo problem, i.e. the problem of establishing correspondences between a pair of images taken from different viewpoints is studied.

A new set of image elements that are put into correspondence, the so called extremal regions, is introduced. Extremal regions possess highly desirable properties: the set is closed under (1) continuous (and thus projective) transformation of image coordinates and (2) monotonic transformation of image intensities. An efficient (near linear complexity) and practically fast detection algorithm (near frame rate) is presented for an affinely invariant stable subset of extremal regions, the maximally stable extremal regions (MSER).

A new robust similarity measure for establishing tentative correspondences is proposed. The robustness ensures that invariants from multiple measurement regions (regions obtained by invariant constructions from extremal regions), some that are significantly larger (and hence discriminative) than the MSERs, may be used to establish tentative correspondences.

The high utility of MSERs, multiple measurement regions and the robust metric is demonstrated in wide-baseline experiments on image pairs from both indoor and outdoor scenes. Significant change of scale (3.5×), illumination conditions, out-of-plane rotation, occlusion, locally anisotropic scale change and 3D translation of the viewpoint are all present in the test problems. Good estimates of epipolar geometry (average distance from corresponding points to the epipolar line below 0.09 of the inter-pixel distance) are obtained.},
	number = {10},
	urldate = {2015-03-11},
	journal = {Image and Vision Computing},
	author = {Matas, J and Chum, O and Urban, M and Pajdla, T},
	month = sep,
	year = {2004},
	keywords = {Distinguished regions, Maximally stable extremal regions, MSER, Robust metric, Wide-baseline stereo},
	pages = {761--767},
	file = {ScienceDirect Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/FB5JX626/Matas et al. - 2004 - Robust wide-baseline stereo from maximally stable .pdf:application/pdf;ScienceDirect Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/S4SMNGPN/S0262885604000435.html:text/html}
}

@article{bay_speeded-up_2008,
	series = {Similarity {Matching} in {Computer} {Vision} and {Multimedia}},
	title = {Speeded-{Up} {Robust} {Features} ({SURF})},
	volume = {110},
	issn = {1077-3142},
	url = {http://www.sciencedirect.com/science/article/pii/S1077314207001555},
	doi = {10.1016/j.cviu.2007.09.014},
	abstract = {This article presents a novel scale- and rotation-invariant detector and descriptor, coined SURF (Speeded-Up Robust Features). SURF approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster.

This is achieved by relying on integral images for image convolutions; by building on the strengths of the leading existing detectors and descriptors (specifically, using a Hessian matrix-based measure for the detector, and a distribution-based descriptor); and by simplifying these methods to the essential. This leads to a combination of novel detection, description, and matching steps.

The paper encompasses a detailed description of the detector and descriptor and then explores the effects of the most important parameters. We conclude the article with SURF’s application to two challenging, yet converse goals: camera calibration as a special case of image registration, and object recognition. Our experiments underline SURF’s usefulness in a broad range of topics in computer vision.},
	number = {3},
	urldate = {2015-03-11},
	journal = {Computer Vision and Image Understanding},
	author = {Bay, Herbert and Ess, Andreas and Tuytelaars, Tinne and Van Gool, Luc},
	month = jun,
	year = {2008},
	keywords = {Camera calibration, Feature description, interest points, local features, Object recognition},
	pages = {346--359},
	file = {ScienceDirect Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/FZHGP2JC/Bay et al. - 2008 - Speeded-Up Robust Features (SURF).pdf:application/pdf;ScienceDirect Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/B7C4D7BC/S1077314207001555.html:text/html}
}

@article{mikolajczyk_performance_2005,
	title = {A performance evaluation of local descriptors},
	volume = {27},
	issn = {0162-8828},
	doi = {10.1109/TPAMI.2005.188},
	abstract = {In this paper, we compare the performance of descriptors computed for local interest regions, as, for example, extracted by the Harris-Affine detector [Mikolajczyk, K and Schmid, C, 2004]. Many different descriptors have been proposed in the literature. It is unclear which descriptors are more appropriate and how their performance depends on the interest region detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the detector. Our evaluation uses as criterion recall with respect to precision and is carried out for different image transformations. We compare shape context [Belongie, S, et al., April 2002], steerable filters [Freeman, W and Adelson, E, Setp. 1991], PCA-SIFT [Ke, Y and Sukthankar, R, 2004], differential invariants [Koenderink, J and van Doorn, A, 1987], spin images [Lazebnik, S, et al., 2003], SIFT [Lowe, D. G., 1999], complex filters [Schaffalitzky, F and Zisserman, A, 2002], moment invariants [Van Gool, L, et al., 1996], and cross-correlation for different types of interest regions. We also propose an extension of the SIFT descriptor and show that it outperforms the original method. Furthermore, we observe that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best. Moments and steerable filters show the best performance among the low dimensional descriptors.},
	number = {10},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Mikolajczyk, K. and Schmid, C.},
	month = oct,
	year = {2005},
	keywords = {Algorithms, Artificial Intelligence, complex filters, Computer simulation, correlation methods, cross-correlation, Data Interpretation, Statistical, Detectors, filtering theory, Filters, image classification, Image databases, Image Enhancement, Image Interpretation, Computer-Assisted, image matching, image recognition, Image retrieval, image transformations, Index Terms- Local descriptors, information retrieval, Information Storage and Retrieval, interest points, interest regions, invariance, Layout, local descriptors, matching, Models, Statistical, moment invariants, Pattern Recognition, Automated, performance evaluation, recognition., Robustness, Software, Software Validation, Spatial databases, spin images, steerable filters},
	pages = {1615--1630},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/RRQUK6Z4/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/V8QK72DG/Mikolajczyk and Schmid - 2005 - A performance evaluation of local descriptors.pdf:application/pdf}
}

@inproceedings{moulin_fusion_2010,
	title = {Fusion of tf. idf weighted bag of visual features for image classification},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5529901},
	urldate = {2015-03-17},
	booktitle = {Content-{Based} {Multimedia} {Indexing} ({CBMI}), 2010 {International} {Workshop} on},
	publisher = {IEEE},
	author = {Moulin, Christophe and Barat, Cécile and Ducottet, Christophe},
	year = {2010},
	pages = {1--6},
	file = {05529901.pdf:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/JJ2NKKPZ/05529901.pdf:application/pdf}
}

@article{oie_multisensory_2002,
	series = {Multisensory {Proceedings}},
	title = {Multisensory fusion: simultaneous re-weighting of vision and touch for the control of human posture},
	volume = {14},
	issn = {0926-6410},
	shorttitle = {Multisensory fusion},
	url = {http://www.sciencedirect.com/science/article/pii/S092664100200071X},
	doi = {10.1016/S0926-6410(02)00071-X},
	abstract = {We examined the generally held belief that the postural control system is able to re-weight its available sensory inputs in order to optimize stance control in altered sensory environments. Our view is that previous accounts of sensory re-weighting provide only indirect evidence, which is subject to alternative explanations. The present results provide strong evidence for sensory re-weighting as the primary mechanism for changes observed in postural sway between conditions. Subjects were presented with small-amplitude, oscillatory visual and somatosensory stimuli at 0.20 and 0.28 Hz, respectively, in five conditions that manipulated the amplitudes of stimulus motion. Gain calculated in each trial with respect to each of the two stimuli was found to change systematically as stimulus motion amplitudes changed across condition. The observed pattern of gain rules out a constant-weight, linear account of posture and is consistent with the re-weighting hypothesis. Parameter fits of a third-order, linear stochastic model to postural sway trajectories in each condition showed that changes in gain across condition were primarily due to changes in coupling coefficients rather than changes in parameters that characterize the stability of the postural system. Visual gain was found to depend upon visual motion amplitude and touch gain was found to depend upon touch motion amplitude, indicating intra-modality dependencies. Visual gain also depended upon touch motion amplitude, indicating an inter-modality dependence. To our knowledge, simultaneous re-weighting of more than one sensory input has never been rigorously demonstrated. These techniques may be able to resolve the source of balance control deficits across populations with far more certainty than currently possible.},
	number = {1},
	urldate = {2015-03-21},
	journal = {Cognitive Brain Research},
	author = {Oie, Kelvin S and Kiemel, Tim and Jeka, John J},
	month = jun,
	year = {2002},
	keywords = {Human, Multisensory, Posture, Sensorimotor, Somatosensation, vision},
	pages = {164--176},
	file = {ScienceDirect Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/P729Z4MC/Oie et al. - 2002 - Multisensory fusion simultaneous re-weighting of .pdf:application/pdf;ScienceDirect Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/C4JXR9FH/S092664100200071X.html:text/html}
}

@article{fetsch_bridging_2013,
	title = {Bridging the gap between theories of sensory cue integration and the physiology of multisensory neurons},
	volume = {14},
	copyright = {© 2013 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1471-003X},
	url = {http://www.nature.com/nrn/journal/v14/n6/abs/nrn3503.html},
	doi = {10.1038/nrn3503},
	abstract = {The richness of perceptual experience, as well as its usefulness for guiding behaviour, depends on the synthesis of information across multiple senses. Recent decades have witnessed a surge in our understanding of how the brain combines sensory cues. Much of this research has been guided by one of two distinct approaches: one is driven primarily by neurophysiological observations, and the other is guided by principles of mathematical psychology and psychophysics. Conflicting results and interpretations have contributed to a conceptual gap between psychophysical and physiological accounts of cue integration, but recent studies of visual–vestibular cue integration have narrowed this gap considerably.
View full text},
	language = {en},
	number = {6},
	urldate = {2015-03-21},
	journal = {Nature Reviews Neuroscience},
	author = {Fetsch, Christopher R. and DeAngelis, Gregory C. and Angelaki, Dora E.},
	month = jun,
	year = {2013},
	pages = {429--442},
	file = {Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/TR93MEBE/Fetsch et al. - 2013 - Bridging the gap between theories of sensory cue i.pdf:application/pdf;Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/6EFUJWF2/nrn3503.html:text/html}
}

@article{calvert_multisensory_2004,
	series = {Representation of 3-{D} {Space} {Using} {Different} {Senses} {In} {Different} {Species}},
	title = {Multisensory integration: methodological approaches and emerging principles in the human brain},
	volume = {98},
	issn = {0928-4257},
	shorttitle = {Multisensory integration},
	url = {http://www.sciencedirect.com/science/article/pii/S0928425704000804},
	doi = {10.1016/j.jphysparis.2004.03.018},
	abstract = {Understanding the conditions under which the brain integrates the different sensory streams and the mechanisms supporting this phenomenon is now a question at the forefront of neuroscience. In this paper, we discuss the opportunities for investigating these multisensory processes using modern imaging techniques, the nature of the information obtainable from each method and their benefits and limitations. Despite considerable variability in terms of paradigm design and analysis, some consistent findings are beginning to emerge. The detection of brain activity in human neuroimaging studies that resembles multisensory integration responses at the cellular level in other species, suggests similar crossmodal binding mechanisms may be operational in the human brain. These mechanisms appear to be distributed across distinct neuronal networks that vary depending on the nature of the shared information between different sensory cues. For example, differing extents of correspondence in time, space or content seem to reliably bias the involvement of different integrative networks which code for these cues. A combination of data obtained from haemodynamic and electromagnetic methods, which offer high spatial or temporal resolution respectively, are providing converging evidence of multisensory interactions at both “early” and “late” stages of processing––suggesting a cascade of synergistic processes operating in parallel at different levels of the cortex.},
	number = {1–3},
	urldate = {2015-03-21},
	journal = {Journal of Physiology-Paris},
	author = {Calvert, Gemma A. and Thesen, Thomas},
	month = jan,
	year = {2004},
	keywords = {FMRI, Imaging, MEG, multisensory integration},
	pages = {191--205},
	file = {ScienceDirect Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/XX2FEHE2/S0928425704000804.html:text/html}
}

@article{deneve_bayesian_2004,
	series = {Representation of 3-{D} {Space} {Using} {Different} {Senses} {In} {Different} {Species}},
	title = {Bayesian multisensory integration and cross-modal spatial links},
	volume = {98},
	issn = {0928-4257},
	url = {http://www.sciencedirect.com/science/article/pii/S0928425704000841},
	doi = {10.1016/j.jphysparis.2004.03.011},
	abstract = {Our perception of the word is the result of combining information between several senses, such as vision, audition and proprioception. These sensory modalities use widely different frames of reference to represent the properties and locations of object. Moreover, multisensory cues come with different degrees of reliability, and the reliability of a given cue can change in different contexts. The Bayesian framework––which we describe in this review––provides an optimal solution to deal with this issue of combining cues that are not equally reliable. However, this approach does not address the issue of frames of references. We show that this problem can be solved by creating cross-modal spatial links in basis function networks. Finally, we show how the basis function approach can be combined with the Bayesian framework to yield networks that can perform optimal multisensory combination. On the basis of this theory, we argue that multisensory integration is a dialogue between sensory modalities rather that the convergence of all sensory information onto a supra-modal area.},
	number = {1–3},
	urldate = {2015-03-21},
	journal = {Journal of Physiology-Paris},
	author = {Deneve, Sophie and Pouget, Alexandre},
	month = jan,
	year = {2004},
	keywords = {Basis functions, Bayesian, Frames of reference, Gain modulation, multisensory integration, Partially shifting receptive fields, Recurrent networks},
	pages = {249--258},
	file = {ScienceDirect Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/Q2K9AVWV/S0928425704000841.html:text/html}
}

@inproceedings{cao_optimization-based_2014,
	title = {Optimization-based multikernel extreme learning for multimodal object image classification},
	doi = {10.1109/MFI.2014.6997629},
	abstract = {This paper is concerned with multi-kernel extreme learning machine (MK-ELM) which adapts the multi-kernel learning (MKL) framework to extreme learning machine (ELM). MK-ELM approach iteratively determines the combination of kernels by gradient descent wrapping a standard optimization method based ELM. Such MKL methods are very useful in information fusion research and applications. MK-ELM's performance on object image classification via multimodal feature (visual and textual) fusion is experimented and studied. By comparing to other widely used fusion methods (i.e. SVM-based SimpleMKL, feature concatenation, and decision fusion), several advantages and characteristics of MK-ELM fusion are revealed and discussed showing MK-ELM is an easy and effective approach to implement in object image classification applications.},
	booktitle = {2014 {International} {Conference} on {Multisensor} {Fusion} and {Information} {Integration} for {Intelligent} {Systems} ({MFI})},
	author = {Cao, Le-le and Huang, Wen-bing and Sun, Fu-chun},
	month = sep,
	year = {2014},
	keywords = {gradient descent wrapping, gradient methods, Histograms, image classification, information fusion applications, information fusion research, Kernel, learning (artificial intelligence), MK-ELM fusion, multimodal feature, multimodal object image classification, optimisation, optimization-based multikernel extreme learning machine, optimization method, Optimization methods, Standards, Support vector machines, textual fusion, Training, visual fusion, Visualization},
	pages = {1--9},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/U65HJBGP/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/QEGDWVIV/Cao et al. - 2014 - Optimization-based multikernel extreme learning fo.pdf:application/pdf}
}

@article{atrey_multimodal_2010,
	title = {Multimodal fusion for multimedia analysis: a survey},
	volume = {16},
	issn = {0942-4962, 1432-1882},
	shorttitle = {Multimodal fusion for multimedia analysis},
	url = {http://link.springer.com/article/10.1007/s00530-010-0182-0},
	doi = {10.1007/s00530-010-0182-0},
	abstract = {This survey aims at providing multimedia researchers with a state-of-the-art overview of fusion strategies, which are used for combining multiple modalities in order to accomplish various multimedia analysis tasks. The existing literature on multimodal fusion research is presented through several classifications based on the fusion methodology and the level of fusion (feature, decision, and hybrid). The fusion methods are described from the perspective of the basic concept, advantages, weaknesses, and their usage in various analysis tasks as reported in the literature. Moreover, several distinctive issues that influence a multimodal fusion process such as, the use of correlation and independence, confidence level, contextual information, synchronization between different modalities, and the optimal modality selection are also highlighted. Finally, we present the open issues for further research in the area of multimodal fusion.},
	language = {en},
	number = {6},
	urldate = {2015-03-25},
	journal = {Multimedia Systems},
	author = {Atrey, Pradeep K. and Hossain, M. Anwar and Saddik, Abdulmotaleb El and Kankanhalli, Mohan S.},
	month = apr,
	year = {2010},
	keywords = {Computer Communication Networks, Computer Graphics, Data Encryption, Data Storage Representation, Multimedia analysis, Multimedia Information Systems, Multimodal information fusion, Operating Systems},
	pages = {345--379},
	file = {Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/4FTIXCXK/Atrey et al. - 2010 - Multimodal fusion for multimedia analysis a surve.pdf:application/pdf;Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/GU8RG47C/s00530-010-0182-0.html:text/html}
}

@inproceedings{hsu_generative_2004,
	title = {Generative, discriminative, and ensemble learning on multi-modal perceptual fusion toward news video story segmentation},
	volume = {2},
	doi = {10.1109/ICME.2004.1394400},
	abstract = {News video story segmentation is a critical task for automatic video indexing and summarization. Our prior work has demonstrated promising performance by using a generative model, called maximum entropy (ME), which models the posterior probability given the multi-modal perceptual features near the candidate points. In this paper, we investigate alternative statistical approaches based on discriminative models, i.e. support vector machine (SVM), and ensemble learning, i.e. boosting. In addition, we develop a novel approach, called BoostME, which uses the ME classifiers and the associated confidence scores in each boosting iteration. We evaluated these different methods using the TRECVID 2003 broadcast news data set. We found that SVM-based and ME-based techniques both outperformed the pure boosting techniques, with the SVM-based solutions achieving even slightly higher accuracy. Moreover, we summarize extensive analysis results of error sources over distinctive news story types to identify future research opportunities},
	booktitle = {2004 {IEEE} {International} {Conference} on {Multimedia} and {Expo}, 2004. {ICME} '04},
	author = {Hsu, H.-M. and Chang, Shih-Fu},
	month = jun,
	year = {2004},
	keywords = {automatic video indexing, Boosting, boosting iteration, BoostME, Broadcasting, confidence scores, content-based retrieval, database indexing, discriminative learning, ensemble learning, Entropy, Error analysis, Fusion power generation, Image retrieval, Indexing, iterative methods, learning (artificial intelligence), Machine learning, maximum entropy, maximum entropy methods, ME classifiers, multimedia databases, multi-modal perceptual fusion, news video story segmentation, probability, Statistical analysis, statistical approaches, support vector machine, Support vector machine classification, Support vector machines, SVM, TRECVID 2003, video coding, video databases, video summarization},
	pages = {1091--1094 Vol.2},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/X72EUUU8/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/HCXHSEQF/Hsu and Chang - 2004 - Generative, discriminative, and ensemble learning .pdf:application/pdf}
}

@article{hall_introduction_1997,
	title = {An introduction to multisensor data fusion},
	volume = {85},
	issn = {0018-9219},
	doi = {10.1109/5.554205},
	abstract = {Multisensor data fusion is an emerging technology applied to Department of Defense (DoD) areas such as automated target recognition, battlefield surveillance, and guidance and control of autonomous vehicles, and to non-DoD applications such as monitoring of complex machinery, medical diagnosis, and smart buildings. Techniques for multisensor data fusion are drawn from a wide range of areas including artificial intelligence, pattern recognition, statistical estimation and other areas. This paper provides a tutorial on data fusion, introducing data fusion applications, process models, and identification of applicable techniques. Comments are made on the state-of-the-art in data fusion},
	number = {1},
	journal = {Proceedings of the IEEE},
	author = {Hall, D.L. and Llinas, J.},
	month = jan,
	year = {1997},
	keywords = {aerospace computing, Artificial Intelligence, automated target recognition, Automatic control, autonomous vehicles, battlefield surveillance, Biomedical monitoring, complex machinery, computerised instrumentation, Computerized monitoring, Condition monitoring, control, Department of Defense, DoD, emerging technology, guidance, identification, Intelligent vehicles, knowledge based methods, knowledge based systems, medical diagnosis, military computing, military systems, mobile robots, multisensor data fusion, Navigation, nonlinearities, Pattern Recognition, process models, Remotely operated vehicles, sensor fusion, smart buildings, statistical estimation, Surveillance, Target recognition},
	pages = {6--23},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/UZWRSHUP/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/5HA9AMGC/Hall and Llinas - 1997 - An introduction to multisensor data fusion.pdf:application/pdf}
}

@inproceedings{pitsikalis_adaptive_2006,
	title = {Adaptive multimodal fusion by uncertainty compensation.},
	url = {http://cvsp.cs.ntua.gr/projects/pub/HIWIRE/HiwirePublications/PitsikalisKatsamanisPapandreouMaragos_AdaptiveFusionUncertaintyCompensation_ICSLP06.pdf},
	urldate = {2015-03-26},
	booktitle = {{INTERSPEECH}},
	author = {Pitsikalis, Vassilis and Katsamanis, Athanassios and Papandreou, George and Maragos, Petros},
	year = {2006},
	file = {PitsikalisKatsamanisPapandreouMaragos_AdaptiveFusionUncertaintyCompensation_ICSLP06.pdf:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/EBIZ48HP/PitsikalisKatsamanisPapandreouMaragos_AdaptiveFusionUncertaintyCompensation_ICSLP06.pdf:application/pdf}
}

@article{meyer_continuous_2004,
	series = {Robust {Speech} {Processing}},
	title = {Continuous audio–visual digit recognition using {N}-best decision fusion},
	volume = {5},
	issn = {1566-2535},
	url = {http://www.sciencedirect.com/science/article/pii/S1566253503000915},
	doi = {10.1016/j.inffus.2003.07.001},
	abstract = {Audio–visual speech recognition systems can be categorised into systems that integrate audio–visual features before decisions are made (feature fusion) and those that integrate decisions of separate recognisers for each modality (decision fusion). Decision fusion has been applied at the level of individual analysis time frames, phone segments and for isolated word recognition but in its basic form cannot be used for continuous speech recognition because of the combinatorial explosion of possible word string hypotheses that have to be evaluated.

We present a case for decision fusion at the utterance level and propose an algorithm that can be applied efficiently to continuous speech recognition tasks, which we call N-best decision fusion. The system was tested on a single-speaker, continuous digit recognition task where the audio stream was contaminated by additive multi-speaker babble noise.

The audio–visual recognition system resulted in lower word error rates for all signal-to-noise conditions tested compared to the audio-alone system. The magnitude of the improvement was dependent on the signal-to-noise ratio.},
	number = {2},
	urldate = {2015-03-26},
	journal = {Information Fusion},
	author = {Meyer, Georg F and Mulligan, Jeffrey B and Wuerger, Sophie M},
	month = jun,
	year = {2004},
	keywords = {Audio–visual speech, Decision fusion, Lip reading, Speech recognition},
	pages = {91--101},
	file = {ScienceDirect Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/2FSFKF7M/S1566253503000915.html:text/html}
}

@article{mitra_gesture_2007,
	title = {Gesture {Recognition}: {A} {Survey}},
	volume = {37},
	issn = {1094-6977},
	shorttitle = {Gesture {Recognition}},
	doi = {10.1109/TSMCC.2007.893280},
	abstract = {Gesture recognition pertains to recognizing meaningful expressions of motion by a human, involving the hands, arms, face, head, and/or body. It is of utmost importance in designing an intelligent and efficient human-computer interface. The applications of gesture recognition are manifold, ranging from sign language through medical rehabilitation to virtual reality. In this paper, we provide a survey on gesture recognition with particular emphasis on hand gestures and facial expressions. Applications involving hidden Markov models, particle filtering and condensation, finite-state machines, optical flow, skin color, and connectionist models are discussed in detail. Existing challenges and future research possibilities are also highlighted},
	number = {3},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C: Applications and Reviews},
	author = {Mitra, S. and Acharya, T.},
	month = may,
	year = {2007},
	keywords = {Arm, condensation, connectionist models, face recognition, facial expressions, Filtering, finite state machines, finite-state machines, gesture recognition, hand gestures, Handicapped aids, Hidden Markov models, hidden Markov models (HMMs), human computer interaction, Humans, image colour analysis, image sequences, intelligent human-computer interface, Magnetic heads, Manifolds, Optical filters, optical flow, particle filtering, skin color, soft computing, Virtual reality},
	pages = {311--324},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/DZ7XNABU/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/WA4SEB8A/Mitra and Acharya - 2007 - Gesture Recognition A Survey.pdf:application/pdf}
}

@article{sinapov_grounding_2014,
	series = {Special {Issue} {Semantic} {Perception}, {Mapping} and {Exploration}},
	title = {Grounding semantic categories in behavioral interactions: {Experiments} with 100 objects},
	volume = {62},
	issn = {0921-8890},
	shorttitle = {Grounding semantic categories in behavioral interactions},
	url = {http://www.sciencedirect.com/science/article/pii/S092188901200190X},
	doi = {10.1016/j.robot.2012.10.007},
	abstract = {From an early stage in their development, human infants show a profound drive to explore the objects around them. Research in psychology has shown that this exploration is fundamental for learning the names of objects and object categories. To address this problem in robotics, this paper presents a behavior-grounded approach that enables a robot to recognize the semantic labels of objects using its own behavioral interaction with them. To test this method, our robot interacted with 100 different objects grouped according to 20 different object categories. The robot performed 10 different behaviors on them, while using three sensory modalities (vision, proprioception and audio) to detect any perceptual changes. The results show that the robot was able to use multiple sensorimotor contexts in order to recognize a large number of object categories. Furthermore, the category recognition model presented in this paper was able to identify sensorimotor contexts that can be used to detect specific categories. Most importantly, the robot’s model was able to reduce exploration time by half by dynamically selecting which exploratory behavior should be applied next when classifying a novel object.},
	number = {5},
	urldate = {2015-04-09},
	journal = {Robotics and Autonomous Systems},
	author = {Sinapov, Jivko and Schenck, Connor and Staley, Kerrick and Sukhoy, Vladimir and Stoytchev, Alexander},
	month = may,
	year = {2014},
	keywords = {Active and interactive perception, Behavior-based robotics, Category recognition, Developmental robotics, Learning and adaptive system, Semantic perception},
	pages = {632--645},
	file = {ScienceDirect Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/BAQ5KFM8/S092188901200190X.html:text/html}
}

@inproceedings{sinapov_learning_2014,
	title = {Learning relational object categories using behavioral exploration and multimodal perception},
	doi = {10.1109/ICRA.2014.6907696},
	abstract = {This paper proposes a framework for learning human-provided category labels that describe individual objects, pairwise object relationships, as well as groups of objects. The framework was evaluated using an experiment in which the robot interactively explored 36 objects that varied by color, weight, and contents. The proposed method allowed the robot not only to learn categories describing individual objects, but also to learn categories describing pairs and groups of objects with high recognition accuracy. Furthermore, by grounding the category representations in its own sensorimotor repertoire, the robot was able to estimate how similar two categories are in terms of the behaviors and sensory modalities that are used to recognize them. Finally, this grounded measure of similarity enabled the robot to boost its recognition performance when learning a new category by relating it to a set of familiar categories.},
	booktitle = {2014 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Sinapov, J. and Schenck, C. and Stoytchev, A.},
	month = may,
	year = {2014},
	keywords = {behavioral exploration, category representation, Context, feature extraction, human-provided category label learning, Image color analysis, image colour analysis, individual objects, learning (artificial intelligence), multimodal perception, object color, object content, object groups, Object recognition, object weight, pairwise object relationships, recognition performance, relational object category learning, robot interactive exploration, Robot sensing systems, robot vision, sensorimotor repertoire, sensory modality, similarity measure, Vectors, Visualization},
	pages = {5691--5698},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/FIAXQZH9/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/FS8NCHIT/Sinapov et al. - 2014 - Learning relational object categories using behavi.pdf:application/pdf}
}

@inproceedings{ngiam_multimodal_2011,
	title = {Multimodal deep learning},
	url = {http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Ngiam_399.pdf},
	urldate = {2015-04-16},
	booktitle = {Proceedings of the 28th {International} {Conference} on {Machine} {Learning} ({ICML}-11)},
	author = {Ngiam, Jiquan and Khosla, Aditya and Kim, Mingyu and Nam, Juhan and Lee, Honglak and Ng, Andrew Y.},
	year = {2011},
	pages = {689--696},
	file = {ICML2011Ngiam_399.pdf:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/K7P8WC9C/ICML2011Ngiam_399.pdf:application/pdf}
}

@article{monaci_modelling_2007,
	title = {On the modelling of multi-modal data using redundant dictionaries},
	url = {http://infoscience.epfl.ch/record/98526},
	urldate = {2015-04-16},
	author = {Monaci, Gianluca},
	year = {2007},
	file = {EPFL_TH3741.pdf:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/M8WXFHA2/EPFL_TH3741.pdf:application/pdf}
}

@inproceedings{nakamura_bag_2012,
	title = {Bag of multimodal hierarchical dirichlet processes: {Model} of complex conceptual structure for intelligent robots},
	shorttitle = {Bag of multimodal hierarchical dirichlet processes},
	doi = {10.1109/IROS.2012.6385502},
	abstract = {The formation of categories, which constitutes the basis of developing concepts, requires multimodal information with a complex structure. We propose a model called the bag of multimodal hierarchical Dirichlet processes (BoMHDP), which enables robots to form a variety of multimodal categories. The BoMHDP model is a collection of a large number of MHDP models, each of which has a different set of weights for sensory information. The weights work to realize selective attention and enable the formation of various types of categories (e.g., object, haptic, and color). The BoMHDP model is an extension of the HDP, and categorization is unsupervised. However, categories that are not natural for humans are also formed. Therefore, only the significant categories are selected through interaction between the user and the robot. At the same time, words obtained during the interaction are connected to the categories. Finally, categories, which are represented by words, are selected. The BoMHDP model was implemented on a robot platform and a preliminary experiment was conducted to validate it. The results revealed that various categories can be formed with the BoMHDP model. We also analyzed the formed conceptual structure by using multidimensional scaling. The results indicate that the complex conceptual structure was represented reasonably well with the BoMHDP model.},
	booktitle = {2012 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	author = {Nakamura, T. and Nagai, T. and Iwahashi, N.},
	month = oct,
	year = {2012},
	keywords = {bag of multimodal hierarchical Dirichlet processes model, BoMHDP model, Color, complex conceptual structure model, haptic interfaces, human-robot interaction, intelligent robots, multidimensional scaling, Multidimensional systems, multimodal information, Mutual information, robot platform, Robot sensing systems, robot vision, selective attention, sensory information, unsupervised categorization, Vectors, Visualization},
	pages = {3818--3823},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/MHUX4QGP/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/DFS5ERZP/Nakamura et al. - 2012 - Bag of multimodal hierarchical dirichlet processes.pdf:application/pdf}
}